{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the RL BR policy training\n",
    "\n",
    "In this notebook we plot the learning curves for the RL-BR policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from posggym_baselines.config import REPO_DIR\n",
    "\n",
    "sys.path.insert(0, str(REPO_DIR / \"baseline_exps\"))\n",
    "import exp_utils\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "SAVE_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_ENV_DATA = exp_utils.load_all_env_data()\n",
    "for k in ALL_ENV_DATA:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR Policy Learning Curves\n",
    "\n",
    "Here we plot the learning curves for the BR policies trained on `P0` and `P1` for each environment. \n",
    "\n",
    "We use a separate plot for each population for each environment, and plot each training seed as a separate line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cleans the raw data downloaded from wandb\n",
    "# - removing weird names\n",
    "# - removing the __MIN and __MAX columns\n",
    "# - updating column names\n",
    "# - reformating the data to use a seed column instead of separate columns for each seed\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    for pop_id, results_file in env_data.rl_br_training_results_files.items():\n",
    "        results_df = pd.read_csv(results_file)\n",
    "        if \"global_step\" not in results_df.columns:\n",
    "            # already cleaned\n",
    "            continue\n",
    "        \n",
    "        columns_to_drop = []\n",
    "        step_col_to_keep = None\n",
    "        for col in results_df.columns:\n",
    "            if col.endswith(\"__MIN\") or col.endswith(\"__MAX\"):\n",
    "                columns_to_drop.append(col)\n",
    "            elif col != \"global_step\" and col.endswith(\"_step\"):\n",
    "                if step_col_to_keep is None:\n",
    "                    step_col_to_keep = col\n",
    "                else:\n",
    "                    columns_to_drop.append(col)\n",
    "        results_df = results_df.drop(columns=columns_to_drop)\n",
    "\n",
    "        column_rename_map = {}\n",
    "        seeds = []\n",
    "        for col in results_df.columns:\n",
    "            if col == \"global_step\":\n",
    "                column_rename_map[col] = \"step\"\n",
    "            elif col.endswith(\"_step\"):\n",
    "                column_rename_map[col] = \"update\"\n",
    "            else:\n",
    "                # Format: BR-PPO_<env_id>[_agent_id]_<pop_id>_<seed>_<date>_<time> - policy_stats/BR/mean_episode_return\n",
    "                # e.g. \"BR-PPO_PursuitEvasion-v1_i1_P0_0_20240119_053338 - policy_stats/BR/mean_episode_return\"\n",
    "                assert col.endswith(\"/BR/mean_episode_return\")\n",
    "                tokens = col.split(\"_\")\n",
    "                env_token_idx = tokens.index(env_data.env_id)\n",
    "                if tokens[env_token_idx + 1].startswith(\"i\"):\n",
    "                    seed = int(tokens[env_token_idx + 3])\n",
    "                else:\n",
    "                    seed = int(tokens[env_token_idx + 2])\n",
    "                column_rename_map[col] = seed\n",
    "                seeds.append(seed)\n",
    "\n",
    "        results_df = results_df.rename(columns=column_rename_map)\n",
    "\n",
    "        results_df = results_df.melt(\n",
    "            id_vars=[\"step\", \"update\"], \n",
    "            value_vars=seeds, \n",
    "            var_name=\"seed\", \n",
    "            value_name=\"mean_episode_return\"\n",
    "        )\n",
    "        results_df[\"seed\"] = results_df[\"seed\"].astype(int)\n",
    "        \n",
    "        results_df.to_csv(str(results_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "training_results_dfs = []\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    env_pop_results_df = []\n",
    "    for pop_id, results_file in env_data.rl_br_training_results_files.items():\n",
    "        results_df = pd.read_csv(results_file)\n",
    "        results_df[\"pop_id\"] = pop_id\n",
    "        env_pop_results_df.append(results_df)\n",
    "    env_pop_results_df = pd.concat(env_pop_results_df)\n",
    "    env_pop_results_df[\"full_env_id\"] = full_env_id\n",
    "    training_results_dfs.append(env_pop_results_df)\n",
    "\n",
    "training_results_df = pd.concat(training_results_dfs)\n",
    "\n",
    "full_env_ids = training_results_df[\"full_env_id\"].unique().tolist()\n",
    "full_env_ids.sort()\n",
    "print(\"Full env ids:\", full_env_ids)\n",
    "\n",
    "pop_ids = training_results_df[\"pop_id\"].unique().tolist()\n",
    "pop_ids.sort()\n",
    "print(\"Pop ids:\", pop_ids)\n",
    "\n",
    "seeds = training_results_df[\"seed\"].unique().tolist()\n",
    "seeds.sort()\n",
    "print(\"Seeds:\", seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "pallete = {s: 'grey' for s in seeds}\n",
    "\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, \n",
    "        ncols=2, \n",
    "        figsize=(6, 3), \n",
    "        sharey=True,\n",
    "        sharex=True,\n",
    "    )\n",
    "    env_df = training_results_df[training_results_df[\"full_env_id\"] == full_env_id]\n",
    "    for c, pop_id in enumerate(pop_ids):\n",
    "        ax = axes[c]\n",
    "        pop_df = env_df[env_df[\"pop_id\"] == pop_id]\n",
    "        sns.lineplot(\n",
    "            data=pop_df,\n",
    "            x=\"step\",\n",
    "            y=\"mean_episode_return\",\n",
    "            hue=\"seed\",\n",
    "            palette=pallete,\n",
    "            ax=ax,\n",
    "            legend=False,\n",
    "            alpha=0.5,\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=pop_df,\n",
    "            x=\"step\",\n",
    "            y=\"mean_episode_return\",\n",
    "            ax=ax,\n",
    "            color=sns.color_palette()[0],\n",
    "            legend=False,\n",
    "            errorbar=None,\n",
    "            linewidth=0.75,\n",
    "        )\n",
    "\n",
    "        # Set axis labels\n",
    "        ax.set_ylabel(\"Mean Return\")\n",
    "        ax.set_xlabel(\"Training Step\")\n",
    "        ax.set_title(pop_id)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if SAVE_RESULTS:\n",
    "        fig.savefig(str(env_data.env_data_dir / \"rl_br_learning_curve.pdf\"))\n",
    "    fig.suptitle(full_env_id)\n",
    "    fig.subplots_adjust(top=0.8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgbls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
