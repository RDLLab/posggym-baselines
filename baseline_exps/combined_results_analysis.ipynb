{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analysis of Combined Results\n",
                "\n",
                "Here we explore the performance of the combined planning+RL algorithm across the different environments.\n",
                "\n",
                "For each algorithm we will look at their mean performance (i.e. episode returns) across the different environments. Looking at both in-distribution (planning population matches the test population) and out-of-distribution (planning population does not match the test population) settings.\n",
                "\n",
                "**Note** each experiment run was repeated 5 times (once for each RL policy seed), so we average the results across these 5 runs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from posggym_baselines.config import REPO_DIR\n",
                "\n",
                "sys.path.insert(0, str(REPO_DIR / \"baseline_exps\"))\n",
                "import exp_utils\n",
                "\n",
                "sns.set_theme(style=\"white\")\n",
                "sns.set_context(\"paper\", font_scale=1.5)\n",
                "sns.set_palette(\"colorblind\")\n",
                "\n",
                "SAVE_RESULTS = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ALL_ENV_DATA = exp_utils.load_all_env_data()\n",
                "for k in ALL_ENV_DATA:\n",
                "    print(k)\n",
                "\n",
                "NUM_ENVS = len(ALL_ENV_DATA)\n",
                "\n",
                "# figure parameters\n",
                "FIGSIZE = (10, 10)\n",
                "N_COLS = min(3, NUM_ENVS)\n",
                "N_ROWS = (NUM_ENVS // N_COLS) + int(NUM_ENVS % N_COLS > 0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Planning Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "for env_id, env_data in ALL_ENV_DATA.items():\n",
                "    env_planning_results = pd.read_csv(env_data.combined_results_file)\n",
                "    env_planning_results[\"full_env_id\"] = env_id\n",
                "    results.append(env_planning_results)\n",
                "\n",
                "results_df = pd.concat(results, ignore_index=True)\n",
                "results_df.rename(\n",
                "    columns={\n",
                "        \"planning_pop_id\": \"Planning Population\",\n",
                "        \"test_pop_id\": \"Test Population\",\n",
                "        \"return\": \"Return\",\n",
                "    },\n",
                "    inplace=True,\n",
                ")\n",
                "\n",
                "# Add In/Out of Distribution labels\n",
                "def get_in_out_dist_label(row):\n",
                "    return row[\"Planning Population\"] == row[\"Test Population\"]\n",
                "\n",
                "results_df[\"In Distribution\"] = results_df.apply(\n",
                "    get_in_out_dist_label, axis=1\n",
                ")\n",
                "\n",
                "results_df.sort_values(\n",
                "    by=[\n",
                "        \"alg\", \n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\", \n",
                "        \"search_time_limit\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "max_search_time = results_df[\"search_time_limit\"].max()\n",
                "\n",
                "results_df = results_df[results_df[\"search_time_limit\"].isin([0.05, 0.1, 0.5, 1, 5, 10, 20])]\n",
                "print(results_df[\"search_time_limit\"].unique())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Performance against Planning and Test Populations\n",
                "\n",
                "Here we look at the performance of the RL+Planning algorithm for each planning and test population combination. We look only at the performance of the algorithm given the maximum search time.\n",
                "\n",
                "Dimensions:\n",
                "\n",
                "- Environment\n",
                "- Planning Population\n",
                "- Test Population\n",
                "- Search Time"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the first plot we look at the distribution of the returns for each environment (column) and for each RL policy seed (row)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot = sns.catplot(\n",
                "    data=results_df[\n",
                "        results_df[\"search_time_limit\"] == max_search_time\n",
                "    ],\n",
                "    x=\"Planning Population\",\n",
                "    y=\"Return\",\n",
                "    hue=\"Test Population\",\n",
                "    col=\"full_env_id\",\n",
                "    # col_wrap=N_COLS,\n",
                "    row=\"rl_policy_seed\",\n",
                "    kind=\"violin\",\n",
                "    sharey=True,\n",
                "    height=3,\n",
                "    aspect=1,\n",
                ")\n",
                "\n",
                "del plot"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we look at the same graph but we average the returns across the different RL policy seeds."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot = sns.catplot(\n",
                "    data=results_df[\n",
                "        results_df[\"search_time_limit\"] == max_search_time\n",
                "    ],\n",
                "    x=\"Planning Population\",\n",
                "    y=\"Return\",\n",
                "    hue=\"Test Population\",\n",
                "    col=\"full_env_id\",\n",
                "    col_wrap=N_COLS,\n",
                "    kind=\"violin\",\n",
                "    sharey=True,\n",
                "    height=3,\n",
                "    aspect=1,\n",
                ")\n",
                "\n",
                "del plot"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## In vs Out of Distribution Performance by Environment\n",
                "\n",
                "Here we look at the in-distribution vs out-of-distribution performance of for each environment given the maximum search time. We look both at the distribution of returns and the mean returns.\n",
                "\n",
                "- `x-axis`: Environment\n",
                "- `y-axis`: Mean episode return\n",
                "- `hue/z-axis`: In (True) vs Out (False) of Distribution\n",
                "- `col/figures`: Algorithm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for kind in (\"bar\", \"violin\"):\n",
                "    plot = sns.catplot(\n",
                "        data=results_df[\n",
                "            results_df[\"search_time_limit\"] == max_search_time\n",
                "        ],\n",
                "        x=\"full_env_id\",\n",
                "        y=\"Return\",\n",
                "        hue=\"In Distribution\",\n",
                "        hue_order=[True, False],\n",
                "        # col=\"\",\n",
                "        # col_wrap=N_COLS,\n",
                "        # row=\"alg\",\n",
                "        kind=kind,\n",
                "        sharey=False,\n",
                "        height=4,\n",
                "        aspect=1,\n",
                "    )\n",
                "    plot.set_xticklabels(rotation=90)\n",
                "\n",
                "    if SAVE_RESULTS:\n",
                "        plot.figure.savefig(\n",
                "            exp_utils.ENV_DATA_DIR / f\"combined_id_vs_ood_by_env_results_{kind}.png\", \n",
                "            bbox_inches=\"tight\"\n",
                "        )\n",
                "\n",
                "    del plot"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## In vs Out of Distribution Performance vs Search Time\n",
                "\n",
                "Here we look at the in vs out of distribution performance across search budgets.\n",
                "\n",
                "- `x-axis`: Search time\n",
                "- `y-axis`: Mean episode return\n",
                "- `hue/z-axis`: In (True) vs Out (False) of Distribution\n",
                "- `col/figures`: Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot = sns.relplot(\n",
                "    data=results_df,\n",
                "    x=\"search_time_limit\",\n",
                "    y=\"Return\",\n",
                "    hue=\"In Distribution\",\n",
                "    hue_order=[True, False],\n",
                "    col=\"full_env_id\",\n",
                "    col_wrap=N_COLS,\n",
                "    kind=\"line\",\n",
                "    height=3,\n",
                "    aspect=1.5,\n",
                ")\n",
                "\n",
                "if SAVE_RESULTS:\n",
                "    plot.figure.savefig(\n",
                "        exp_utils.ENV_DATA_DIR / \"combined_id_vs_ood_by_search_time_per_alg.png\",\n",
                "        bbox_inches=\"tight\"\n",
                "    )\n",
                "\n",
                "del plot"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we show the same but averaged across environments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot = sns.relplot(\n",
                "    data=results_df,\n",
                "    x=\"search_time_limit\",\n",
                "    y=\"Return\",\n",
                "    hue=\"In Distribution\",\n",
                "    hue_order=[True, False],\n",
                "    # col=\"full_env_id\",\n",
                "    # col_wrap=N_COLS,\n",
                "    kind=\"line\",\n",
                "    height=4,\n",
                "    aspect=1,\n",
                ")\n",
                "\n",
                "del plot"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Search Statistics\n",
                "\n",
                "Here we look at various statistics of the search process for each algorithm.\n",
                "\n",
                "Each figure is a different statistic, each line is a different environment since we expect some differences between environments based on things like average steps to terminal state. In and out of distribution results are grouped together since we expect and see no different in search statistics between in vs out of distribution.\n",
                "\n",
                "- `x-axis`: Search time\n",
                "- `y-axis`: Search Statistic Values\n",
                "- `col/figures`: Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for stat_key in [\n",
                "    \"update_time\",\n",
                "    \"reinvigoration_time\",\n",
                "    \"evaluation_time\",\n",
                "    \"policy_calls\",\n",
                "    \"inference_time\",\n",
                "    \"search_depth\",\n",
                "    \"num_sims\",\n",
                "    \"mem_usage\",\n",
                "    \"min_value\",\n",
                "    \"max_value\",\n",
                "]:\n",
                "\n",
                "    plot = sns.relplot(\n",
                "        data=results_df,\n",
                "        x=\"search_time_limit\",\n",
                "        y=stat_key,\n",
                "        hue=\"full_env_id\",\n",
                "        # col_wrap=N_COLS,\n",
                "        kind=\"line\",\n",
                "        col=\"Planning Population\",\n",
                "        height=3,\n",
                "        aspect=1.5,\n",
                "    )\n",
                "\n",
                "    del plot"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Belief Statistics\n",
                "\n",
                "Here we look at various statistics of the belief of the agent in each environment, in and out of distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "belief_results_df = []\n",
                "for full_env_id in ALL_ENV_DATA:\n",
                "    env_belief_results = pd.read_csv(\n",
                "        ALL_ENV_DATA[full_env_id].env_data_dir / \"combined_belief_results.csv\"\n",
                "    )\n",
                "    env_belief_results[\"full_env_id\"] = full_env_id\n",
                "    belief_results_df.append(env_belief_results)\n",
                "\n",
                "belief_results_df = pd.concat(belief_results_df, ignore_index=True)\n",
                "belief_results_df.rename(\n",
                "    columns={\n",
                "        \"planning_pop_id\": \"Planning Population\",\n",
                "        \"test_pop_id\": \"Test Population\",\n",
                "        \"return\": \"Return\",\n",
                "        \"belief_state_acc\": \"Belief State Accuracy\",\n",
                "        \"belief_history_acc\": \"Belief History Accuracy\",\n",
                "        \"belief_action_acc\": \"Belief Action Accuracy\",\n",
                "        \"belief_policy_acc\": \"Belief Policy Accuracy\",\n",
                "    },\n",
                "    inplace=True,\n",
                ")\n",
                "\n",
                "# Add In/Out of Distribution labels\n",
                "def get_in_out_dist_label(row):\n",
                "    return row[\"Planning Population\"] == row[\"Test Population\"]\n",
                "\n",
                "belief_results_df[\"In Distribution\"] = belief_results_df.apply(\n",
                "    get_in_out_dist_label, axis=1\n",
                ")\n",
                "\n",
                "belief_results_df.sort_values(\n",
                "    by=[\n",
                "        \"alg\", \n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\", \n",
                "        \"search_time_limit\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "print(belief_results_df[\"search_time_limit\"].unique())\n",
                "print(belief_results_df[\"full_env_id\"].unique())\n",
                "\n",
                "# for c in belief_results_df.columns:\n",
                "#     print(c)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for belief_stat_key in [\n",
                "    \"Belief State Accuracy\",\n",
                "    \"Belief History Accuracy\",\n",
                "    \"Belief Action Accuracy\",\n",
                "    \"Belief Policy Accuracy\",\n",
                "]:\n",
                "    g = sns.relplot(\n",
                "        data=belief_results_df,\n",
                "        x=\"search_time_limit\",\n",
                "        y=belief_stat_key,\n",
                "        hue=\"In Distribution\",\n",
                "        hue_order=[True, False],\n",
                "        col_wrap=N_COLS,\n",
                "        kind=\"line\",\n",
                "        height=3,\n",
                "        aspect=1,\n",
                "        # col=\"Planning Population\",\n",
                "        col=\"full_env_id\",\n",
                "        facet_kws={\n",
                "            \"sharey\": \"row\",\n",
                "            \"sharex\": True, \n",
                "        },\n",
                "    )\n",
                "\n",
                "    # for i, (col_key, ax) in enumerate(g.axes_dict.items()):\n",
                "    #     ax.set_title(col_key)\n",
                "    #     if i % 3 == 0:\n",
                "    #         ax.set_ylabel(\"Mean Return\")\n",
                "    #     if i >= 3:\n",
                "    #         ax.set_xlabel(\"Search Time (s)\")\n",
                "\n",
                "    # for (row_key, col_key), ax in g.axes_dict.items():\n",
                "    #     ax.set_title(f\"{row_key} | {col_key}\")\n",
                "\n",
                "    for col_key, ax in g.axes_dict.items():\n",
                "        ax.set_title(f\"{col_key}\")\n",
                "        ax.set_xlabel(\"Search Time Limit (s)\")\n",
                "\n",
                "    if True:\n",
                "        print(f\"saving {belief_stat_key} figure\")\n",
                "        g.savefig(\n",
                "            exp_utils.ENV_DATA_DIR / \"figures\" / f\"{belief_stat_key}.pdf\", \n",
                "            bbox_inches=\"tight\"\n",
                "        )\n",
                "\n",
                "    del g"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Per Episode Step\n",
                "\n",
                "Here we look at the mean belief statistics per episode step.\n",
                "\n",
                "- `x-axis`: Episode Step\n",
                "- `y-axis`: Belief Statistic Values\n",
                "- `col/figures`: Environment\n",
                "- `hue/z-axis`: Search Time\n",
                "- `style`: In (True) vs Out (False) of Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ps_belief_results_df = []\n",
                "for full_env_id in ALL_ENV_DATA:\n",
                "    print(full_env_id)\n",
                "    env_belief_results = pd.read_csv(\n",
                "        ALL_ENV_DATA[full_env_id].env_data_dir / \"combined_belief_per_step_results.csv\"\n",
                "    )\n",
                "    env_belief_results[\"full_env_id\"] = full_env_id\n",
                "\n",
                "    env_step_limit = max(\n",
                "        int(c.split(\"_\")[-1]) \n",
                "        for c in env_belief_results.columns \n",
                "        if c.startswith(\"belief_state_acc_\")\n",
                "    )\n",
                "    env_belief_results[\"step_limit\"] = env_step_limit\n",
                "\n",
                "    # drop unused columns\n",
                "    # keep only id columns and per step belief stats (remove mean belief stats)\n",
                "    id_cols = [\n",
                "        \"alg\", \n",
                "        \"full_env_id\", \n",
                "        \"planning_pop_id\", \n",
                "        \"test_pop_id\", \n",
                "        \"rl_policy_seed\",\n",
                "        \"search_time_limit\", \n",
                "        \"step_limit\",\n",
                "        \"num\"\n",
                "    ]\n",
                "    cols_to_keep = [*id_cols] + [\n",
                "        c for c in env_belief_results.columns \n",
                "        if c.startswith(\"belief_\") and c.split(\"_\")[-1] != \"acc\"\n",
                "    ]\n",
                "    env_belief_results.drop(\n",
                "        columns=[c for c in env_belief_results.columns if c not in cols_to_keep], \n",
                "        inplace=True\n",
                "    )\n",
                "\n",
                "    # convert from wide to long format for per step belief stats\n",
                "    stub_names = [\n",
                "        k for k in [\n",
                "            \"belief_state_acc\", \n",
                "            \"belief_history_acc\", \n",
                "            \"belief_action_acc\", \n",
                "            \"belief_policy_acc\"\n",
                "        ]\n",
                "        if any(c.startswith(k) for c in env_belief_results.columns)\n",
                "    ]\n",
                "\n",
                "    env_belief_results = pd.wide_to_long(\n",
                "        env_belief_results, \n",
                "        stubnames=stub_names, \n",
                "        i=id_cols, \n",
                "        j=\"step\", \n",
                "        sep=\"_\"\n",
                "    ).reset_index()\n",
                "    ps_belief_results_df.append(env_belief_results)\n",
                "\n",
                "ps_belief_results_df = pd.concat(ps_belief_results_df, ignore_index=True)\n",
                "ps_belief_results_df.rename(\n",
                "    columns={\n",
                "        \"planning_pop_id\": \"Planning Population\",\n",
                "        \"test_pop_id\": \"Test Population\",\n",
                "        \"belief_state_acc\": \"Belief State Accuracy\",\n",
                "        \"belief_history_acc\": \"Belief History Accuracy\",\n",
                "        \"belief_action_acc\": \"Belief Action Accuracy\",\n",
                "        \"belief_policy_acc\": \"Belief Policy Accuracy\",\n",
                "        \"search_time_limit\": \"Search Time (s)\",\n",
                "    },\n",
                "    inplace=True,\n",
                ")\n",
                "\n",
                "# Add In/Out of Distribution labels\n",
                "def get_in_out_dist_label(row):\n",
                "    return row[\"Planning Population\"] == row[\"Test Population\"]\n",
                "\n",
                "ps_belief_results_df[\"In Distribution\"] = ps_belief_results_df.apply(\n",
                "    get_in_out_dist_label, axis=1\n",
                ")\n",
                "\n",
                "ps_belief_results_df.sort_values(\n",
                "    by=[\n",
                "        \"alg\", \n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\", \n",
                "        \"Search Time (s)\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "print(ps_belief_results_df[\"Search Time (s)\"].unique())\n",
                "print(ps_belief_results_df[\"full_env_id\"].unique())\n",
                "print(ps_belief_results_df[\"step\"].min(), ps_belief_results_df[\"step\"].max())\n",
                "\n",
                "# for c in belief_results_df.columns:\n",
                "#     print(c)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for belief_stat_key in [\n",
                "    \"Belief State Accuracy\",\n",
                "    # \"Belief History Accuracy\",\n",
                "    \"Belief Action Accuracy\",\n",
                "    \"Belief Policy Accuracy\",\n",
                "]:\n",
                "    print(belief_stat_key)\n",
                "\n",
                "    if belief_stat_key == \"Belief Policy Accuracy\":\n",
                "        g = sns.relplot(\n",
                "            data=ps_belief_results_df[ps_belief_results_df[\"In Distribution\"] == True],\n",
                "            x=\"step\",\n",
                "            y=belief_stat_key,\n",
                "            hue=\"Search Time (s)\",\n",
                "            col_wrap=N_COLS,\n",
                "            kind=\"line\",\n",
                "            col=\"full_env_id\",\n",
                "            height=3,\n",
                "            aspect=1.5,\n",
                "            facet_kws={\n",
                "                \"sharey\": False,\n",
                "                \"sharex\": False, \n",
                "            },\n",
                "        )\n",
                "    else:\n",
                "        g = sns.relplot(\n",
                "            data=ps_belief_results_df,\n",
                "            x=\"step\",\n",
                "            y=belief_stat_key,\n",
                "            hue=\"Search Time (s)\",\n",
                "            style=\"In Distribution\",\n",
                "            style_order=[True, False],\n",
                "            col_wrap=N_COLS,\n",
                "            kind=\"line\",\n",
                "            col=\"full_env_id\",\n",
                "            height=3,\n",
                "            aspect=1.5,\n",
                "            facet_kws={\n",
                "                \"sharey\": False,\n",
                "                \"sharex\": False, \n",
                "            },\n",
                "        )\n",
                "\n",
                "    for i, (col_key, ax) in enumerate(g.axes_dict.items()):\n",
                "        ax.set_title(f\"{col_key}\")\n",
                "        if i >= N_COLS:\n",
                "            ax.set_xlabel(\"Episode Step\")\n",
                "\n",
                "    if True:\n",
                "        print(f\"saving {belief_stat_key} figure\")\n",
                "        g.savefig(\n",
                "            exp_utils.ENV_DATA_DIR / \"figures\" / f\"per_step_{belief_stat_key}.pdf\", \n",
                "            bbox_inches=\"tight\"\n",
                "        )\n",
                "\n",
                "    del g"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pgbls",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
