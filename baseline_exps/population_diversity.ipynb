{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Populations Diversity\n",
    "\n",
    "In this notebook we explore the diversity of the populations for each environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from posggym_baselines.config import REPO_DIR\n",
    "\n",
    "sys.path.insert(0, str(REPO_DIR / \"baseline_exps\"))\n",
    "import exp_utils\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "SAVE_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_ENV_DATA = exp_utils.load_all_env_data()\n",
    "for k in ALL_ENV_DATA:\n",
    "    print(k)\n",
    "\n",
    "NUM_ENVS = len(ALL_ENV_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Diversity\n",
    "\n",
    "The diversity of a population of policies is calculated by taking the mean of the pairwise distances between the returns of all policies in the population.  The Euclidean distance is used for the distance metric, as it captures the magnitude of the difference between the returns of each policy against each other policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_pop_id(row, full_env_id):\n",
    "    if row[\"policy_name\"] in ALL_ENV_DATA[full_env_id].pop_policy_names[\"P0\"]:\n",
    "        return \"P0\"\n",
    "    if row[\"policy_name\"] in ALL_ENV_DATA[full_env_id].pop_policy_names[\"P1\"]:\n",
    "        return \"P1\"\n",
    "    # not used in exps\n",
    "    return \"P2\"\n",
    "\n",
    "def co_team_name(row):\n",
    "    co_team_id = row[\"co_team_id\"].replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    return co_team_id\n",
    "\n",
    "def co_team_pop_id(row, full_env_id):\n",
    "    if row[\"co_team_name\"] in ALL_ENV_DATA[full_env_id].pop_co_team_names[\"P0\"]:\n",
    "        return \"P0\"\n",
    "    if row[\"co_team_name\"] in ALL_ENV_DATA[full_env_id].pop_co_team_names[\"P1\"]:\n",
    "        return \"P1\"\n",
    "    # not used in exps\n",
    "    return \"P2\"\n",
    "\n",
    "\n",
    "div_results_dfs = []\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    print(full_env_id)\n",
    "    env_div_df = pd.read_csv(env_data.pop_div_results_file)\n",
    "    env_div_df[\"full_env_id\"] = full_env_id\n",
    "    env_div_df[\"agent_id\"] = env_div_df[\"agent_id\"].astype(str)\n",
    "    # drop \"Random-v0\" policy\n",
    "    env_div_df = env_div_df[env_div_df[\"policy_id\"] != \"Random-v0\"]\n",
    "    env_div_df = env_div_df[env_div_df[\"co_team_id\"] != \"(Random)\"]\n",
    "\n",
    "    env_div_df[\"co_team_name\"] = env_div_df.apply(\n",
    "        lambda row: co_team_name(row), axis=1\n",
    "    )\n",
    "    env_div_df[\"policy_pop_id\"] = env_div_df.apply(\n",
    "        lambda row: policy_pop_id(row, full_env_id), axis=1\n",
    "    )\n",
    "    env_div_df[\"co_team_pop_id\"] = env_div_df.apply(\n",
    "        lambda row: co_team_pop_id(row, full_env_id), axis=1\n",
    "    )\n",
    "\n",
    "    if full_env_id == \"Driving-v1\":\n",
    "        env_div_df[\"policy_name\"] = env_div_df[\"policy_name\"].apply(\n",
    "            lambda x: x.replace(\"Shortestpath\", \"\")\n",
    "        )\n",
    "        env_div_df[\"co_team_name\"] = env_div_df[\"co_team_name\"].apply(\n",
    "            lambda x: x.replace(\"Shortestpath\", \"\")\n",
    "        )\n",
    "\n",
    "    # drop unused rows\n",
    "    env_div_df = env_div_df[env_div_df[\"policy_pop_id\"] != \"P2\"]\n",
    "    env_div_df = env_div_df[env_div_df[\"co_team_pop_id\"] != \"P2\"]\n",
    "\n",
    "    # average over any duplicate rows\n",
    "    env_div_df = env_div_df.groupby([\n",
    "        \"env_id\",\n",
    "        \"full_env_id\", \n",
    "        \"policy_name\",\n",
    "        \"co_team_name\",\n",
    "        \"policy_pop_id\", \n",
    "        \"co_team_pop_id\",\n",
    "        \"agent_id\",\n",
    "    ]).agg(\n",
    "        {\"episode_reward_mean\": \"mean\"}\n",
    "    ).reset_index()\n",
    "\n",
    "    env_min_return = env_div_df[\"episode_reward_mean\"].min()\n",
    "    env_max_return = env_div_df[\"episode_reward_mean\"].max()\n",
    "    env_div_df[\"normalized_episode_reward_mean\"] = (\n",
    "        env_div_df[\"episode_reward_mean\"] - env_min_return\n",
    "    ) / (env_max_return - env_min_return)\n",
    "\n",
    "    div_results_dfs.append(env_div_df)\n",
    "\n",
    "div_results_df = pd.concat(div_results_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_policy_name_fn(name):\n",
    "    name = name.split(\"_\")[0]\n",
    "    if name.startswith(\"H\") or name.startswith(\"A\"):\n",
    "        return (name[0], int(name[1:]))\n",
    "    if name.startswith(\"RL\"):\n",
    "        return (name[0:2], int(name[2:]))\n",
    "    if name.startswith(\"KLRBR\"):\n",
    "        return (name[0:5], 1000)\n",
    "    if name.startswith(\"KLR\"):\n",
    "        return (name[0:3], int(name[3:]))\n",
    "    return (name, 0)\n",
    "\n",
    "\n",
    "def sort_index_fn(x: pd.Index, sort_fn=sort_policy_name_fn):\n",
    "    x_list = x.to_list()\n",
    "    x_list.sort(key=sort_fn)\n",
    "    new_positions = [x_list.index(i) for i in x]\n",
    "    return pd.Index(new_positions)\n",
    "\n",
    "\n",
    "def get_env_pw_returns_df(\n",
    "    full_env_id: str, \n",
    "    policy_pop_id: Optional[str] = None, \n",
    "    co_team_pop_id: Optional[str] = None,\n",
    "    values: List[str] = [\"episode_reward_mean\", \"normalized_episode_reward_mean\"],\n",
    "):\n",
    "    env_df = div_results_df[\n",
    "        (div_results_df[\"full_env_id\"] == full_env_id) &\n",
    "        (div_results_df[\"agent_id\"] == ALL_ENV_DATA[full_env_id].agent_id)\n",
    "    ]\n",
    "    if policy_pop_id is not None:\n",
    "        env_df = env_df[env_df[\"policy_pop_id\"] == policy_pop_id]\n",
    "    if co_team_pop_id is not None:\n",
    "        env_df = env_df[env_df[\"co_team_pop_id\"] == co_team_pop_id]\n",
    "    pw_returns_df = env_df.pivot(\n",
    "        index=\"policy_name\", \n",
    "        columns=\"co_team_name\", \n",
    "        values=values\n",
    "    )\n",
    "    pw_returns_df = pw_returns_df.sort_index(\n",
    "        axis='columns',\n",
    "        level=1,\n",
    "        inplace=False,\n",
    "        key=sort_index_fn\n",
    "    )\n",
    "    pw_returns_df = pw_returns_df.sort_index(\n",
    "        axis='rows', # type: ignore\n",
    "        level=0,\n",
    "        inplace=False,\n",
    "        key=sort_index_fn\n",
    "    ) # type: ignore\n",
    "    return pw_returns_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_envs = True\n",
    "\n",
    "if not plot_individual_envs:\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=NUM_ENVS, \n",
    "        ncols=1, \n",
    "        figsize=(6, (NUM_ENVS * 4)+2),\n",
    "        squeeze=False\n",
    "    )\n",
    "else:\n",
    "    fig = None\n",
    "    axes = None\n",
    "\n",
    "pop_div_results_df = []\n",
    "for row, full_env_id in enumerate(ALL_ENV_DATA):\n",
    "    print(full_env_id)\n",
    "    pw_returns_df = get_env_pw_returns_df(full_env_id)\n",
    "\n",
    "    if plot_individual_envs:\n",
    "        fig, env_axes = plt.subplots(\n",
    "            nrows=1, \n",
    "            ncols=1, \n",
    "            figsize=(6, 6),\n",
    "            squeeze=False\n",
    "        )\n",
    "        env_axes = env_axes[0]\n",
    "    else:\n",
    "        assert axes is not None\n",
    "        env_axes = axes[row, :]\n",
    "\n",
    "    sns.heatmap(\n",
    "        data=pw_returns_df[\"episode_reward_mean\"],\n",
    "        ax=env_axes[0],\n",
    "        annot=True,\n",
    "        cmap=\"YlGnBu\",\n",
    "        fmt=\".2f\",\n",
    "        square=True,\n",
    "        annot_kws={\"fontsize\": 6},\n",
    "\n",
    "    )\n",
    "    env_axes[0].set(xlabel=\"Other Agent Policy\", ylabel=\"Policy\")\n",
    "\n",
    "    if not SAVE_RESULTS:\n",
    "        env_axes[0].set_title(f\"Env: {full_env_id}\")\n",
    "\n",
    "    if plot_individual_envs:\n",
    "        assert fig is not None\n",
    "        fig.tight_layout()\n",
    "        if SAVE_RESULTS:\n",
    "            fig.savefig(\n",
    "                str(ALL_ENV_DATA[full_env_id].env_data_dir / \"pairwise_returns.pdf\"), \n",
    "                bbox_inches=\"tight\"\n",
    "            )\n",
    "\n",
    "\n",
    "if not plot_individual_envs:\n",
    "    assert fig is not None\n",
    "    fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgbls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
