{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Population Diversity\n",
    "\n",
    "In this notebook we explore the diversity of the two different populations, `P0` and `P1` for each environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "from posggym_baselines.config import REPO_DIR\n",
    "\n",
    "sys.path.insert(0, pathlib.Path(REPO_DIR) / \"baseline_exps\")\n",
    "import exp_utils\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "SAVE_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_ENV_DATA = exp_utils.load_all_env_data()\n",
    "for k in ALL_ENV_DATA:\n",
    "    print(k)\n",
    "\n",
    "NUM_ENVS = len(ALL_ENV_DATA)\n",
    "\n",
    "# figure parameters\n",
    "FIGSIZE = (10, 10)\n",
    "N_COLS = min(3, NUM_ENVS)\n",
    "N_ROWS = (NUM_ENVS // N_COLS) + int(NUM_ENVS % N_COLS > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_A = np.array([1, 0, 0.25, 0.05])\n",
    "pi_B = np.array([0.5, 0.25, 0.75, 0.2])\n",
    "pi_C = np.array([1, 1, 1, 0.95])\n",
    "pi_D = np.array([0.45, 0.3, 0.2, 0.3])\n",
    "\n",
    "U = np.array([pi_A, pi_B, pi_C, pi_D])\n",
    "D = np.zeros_like(U)\n",
    "for i in range(len(U)):\n",
    "    for j in range(len(U)):\n",
    "        D[i, j] = np.linalg.norm(U[:, i] - U[:, j])\n",
    "\n",
    "# plot the distance matrix\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "sns.heatmap(D, annot=True, fmt=\".2f\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Diversity\n",
    "\n",
    "The diversity of a population of policies is calculated by taking the mean of the pairwise distances between the returns of all policies in the population.  The Euclidean distance is used for the distance metric, as it captures the magnitude of the difference between the returns of each policy against each other policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_pop_id(row, full_env_id):\n",
    "    if row[\"policy_name\"] in ALL_ENV_DATA[full_env_id].pop_policy_names[\"P0\"]:\n",
    "        return \"P0\"\n",
    "    if row[\"policy_name\"] in ALL_ENV_DATA[full_env_id].pop_policy_names[\"P1\"]:\n",
    "        return \"P1\"\n",
    "    # not used in exps\n",
    "    return \"P2\"\n",
    "\n",
    "def co_team_name(row):\n",
    "    co_team_id = row[\"co_team_id\"].replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    return co_team_id\n",
    "\n",
    "def co_team_pop_id(row, full_env_id):\n",
    "    if row[\"co_team_name\"] in ALL_ENV_DATA[full_env_id].pop_co_team_names[\"P0\"]:\n",
    "        return \"P0\"\n",
    "    if row[\"co_team_name\"] in ALL_ENV_DATA[full_env_id].pop_co_team_names[\"P1\"]:\n",
    "        return \"P1\"\n",
    "    # not used in exps\n",
    "    return \"P2\"\n",
    "\n",
    "\n",
    "div_results_df = []\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    print(full_env_id)\n",
    "    env_div_results_df = pd.read_csv(env_data.pop_div_results_file)\n",
    "    env_div_results_df[\"full_env_id\"] = full_env_id\n",
    "    env_div_results_df[\"agent_id\"] = env_div_results_df[\"agent_id\"].astype(str)\n",
    "    # drop \"Random-v0\" policy\n",
    "    env_div_results_df = env_div_results_df[env_div_results_df[\"policy_id\"] != \"Random-v0\"]\n",
    "    env_div_results_df = env_div_results_df[env_div_results_df[\"co_team_id\"] != \"(Random)\"]\n",
    "\n",
    "    env_div_results_df[\"co_team_name\"] = env_div_results_df.apply(\n",
    "        lambda row: co_team_name(row), axis=1\n",
    "    )\n",
    "    env_div_results_df[\"policy_pop_id\"] = env_div_results_df.apply(\n",
    "        lambda row: policy_pop_id(row, full_env_id), axis=1\n",
    "    )\n",
    "    env_div_results_df[\"co_team_pop_id\"] = env_div_results_df.apply(\n",
    "        lambda row: co_team_pop_id(row, full_env_id), axis=1\n",
    "    )\n",
    "\n",
    "    if full_env_id == \"Driving-v1\":\n",
    "        env_div_results_df[\"policy_name\"] = env_div_results_df[\"policy_name\"].apply(\n",
    "            lambda x: x.replace(\"Shortestpath\", \"\")\n",
    "        )\n",
    "        env_div_results_df[\"co_team_name\"] = env_div_results_df[\"co_team_name\"].apply(\n",
    "            lambda x: x.replace(\"Shortestpath\", \"\")\n",
    "        )\n",
    "\n",
    "    # drop unused rows\n",
    "    env_div_results_df = env_div_results_df[env_div_results_df[\"policy_pop_id\"] != \"P2\"]\n",
    "    env_div_results_df = env_div_results_df[env_div_results_df[\"co_team_pop_id\"] != \"P2\"]\n",
    "\n",
    "    # average over any duplicate rows\n",
    "    env_div_results_df = env_div_results_df.groupby([\n",
    "        \"env_id\",\n",
    "        \"full_env_id\", \n",
    "        \"policy_name\",\n",
    "        \"co_team_name\",\n",
    "        \"policy_pop_id\", \n",
    "        \"co_team_pop_id\",\n",
    "        \"agent_id\",\n",
    "    ]).agg(\n",
    "        {\"episode_reward_mean\": \"mean\"}\n",
    "    ).reset_index()\n",
    "\n",
    "    env_min_return = env_div_results_df[\"episode_reward_mean\"].min()\n",
    "    env_max_return = env_div_results_df[\"episode_reward_mean\"].max()\n",
    "    env_div_results_df[\"normalized_episode_reward_mean\"] = (\n",
    "        env_div_results_df[\"episode_reward_mean\"] - env_min_return\n",
    "    ) / (env_max_return - env_min_return)\n",
    "\n",
    "    div_results_df.append(env_div_results_df)\n",
    "\n",
    "div_results_df = pd.concat(div_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "\n",
    "def sort_policy_name_fn(name):\n",
    "    name = name.split(\"_\")[0]\n",
    "    if name.startswith(\"H\") or name.startswith(\"A\"):\n",
    "        return (name[0], int(name[1:]))\n",
    "    if name.startswith(\"RL\"):\n",
    "        return (name[0:2], int(name[2:]))\n",
    "    if name.startswith(\"KLRBR\"):\n",
    "        return (name[0:5], 1000)\n",
    "    if name.startswith(\"KLR\"):\n",
    "        return (name[0:3], int(name[3:]))\n",
    "    return (name, 0)\n",
    "\n",
    "\n",
    "def sort_index_fn(x: pd.Index, sort_fn=sort_policy_name_fn):\n",
    "    x_list = x.to_list()\n",
    "    x_list.sort(key=sort_fn)\n",
    "    new_positions = [x_list.index(i) for i in x]\n",
    "    return pd.Index(new_positions)\n",
    "\n",
    "\n",
    "def get_env_pw_returns_df(\n",
    "    full_env_id: str, \n",
    "    policy_pop_id: Optional[str] = None, \n",
    "    co_team_pop_id: Optional[str] = None,\n",
    "    values: List[str] = [\"episode_reward_mean\", \"normalized_episode_reward_mean\"],\n",
    "):\n",
    "    env_df = div_results_df[\n",
    "        (div_results_df[\"full_env_id\"] == full_env_id) &\n",
    "        (div_results_df[\"agent_id\"] == ALL_ENV_DATA[full_env_id].agent_id)\n",
    "    ]\n",
    "    if policy_pop_id is not None:\n",
    "        env_df = env_df[env_df[\"policy_pop_id\"] == policy_pop_id]\n",
    "    if co_team_pop_id is not None:\n",
    "        env_df = env_df[env_df[\"co_team_pop_id\"] == co_team_pop_id]\n",
    "    pw_returns_df = env_df.pivot(\n",
    "        index=\"policy_name\", \n",
    "        columns=\"co_team_name\", \n",
    "        values=values\n",
    "    )\n",
    "    pw_returns_df = pw_returns_df.sort_index(\n",
    "        axis='columns',\n",
    "        level=1,\n",
    "        inplace=False,\n",
    "        key=sort_index_fn\n",
    "    )\n",
    "    pw_returns_df = pw_returns_df.sort_index(\n",
    "        axis='rows',\n",
    "        level=0,\n",
    "        inplace=False,\n",
    "        key=sort_index_fn\n",
    "    )\n",
    "    return pw_returns_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dendrogram = False\n",
    "plot_individual_envs = True\n",
    "# save_results = SAVE_RESULTS\n",
    "save_results = True\n",
    "\n",
    "if not plot_individual_envs:\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=NUM_ENVS, \n",
    "        ncols=2 if show_dendrogram else 1, \n",
    "        figsize=(10 if show_dendrogram else 6, (NUM_ENVS * 4)+2),\n",
    "        squeeze=False\n",
    "    )\n",
    "else:\n",
    "    fig = None\n",
    "    axes = None\n",
    "\n",
    "pop_div_results_df = []\n",
    "for row, full_env_id in enumerate(ALL_ENV_DATA):\n",
    "    print(full_env_id)\n",
    "    pw_returns_df = get_env_pw_returns_df(full_env_id)\n",
    "\n",
    "    if plot_individual_envs:\n",
    "        fig, env_axes = plt.subplots(\n",
    "            nrows=1, \n",
    "            ncols=2 if show_dendrogram else 1, \n",
    "            figsize=(10 if show_dendrogram else 6, 6),\n",
    "            squeeze=False\n",
    "        )\n",
    "        env_axes = env_axes[0]\n",
    "    else:\n",
    "        assert axes is not None\n",
    "        env_axes = axes[row, :]\n",
    "\n",
    "    sns.heatmap(\n",
    "        data=pw_returns_df[\"episode_reward_mean\"],\n",
    "        ax=env_axes[0],\n",
    "        annot=True,\n",
    "        cmap=\"YlGnBu\",\n",
    "        fmt=\".2f\",\n",
    "        square=True,\n",
    "        annot_kws={\"fontsize\": 6},\n",
    "\n",
    "    )\n",
    "    env_axes[0].set(xlabel=\"Other Agent Policy\", ylabel=\"Policy\")\n",
    "\n",
    "    if not save_results:\n",
    "        env_axes[0].set_title(f\"Env: {full_env_id}\")\n",
    "\n",
    "    if show_dendrogram:\n",
    "        norm_df = pw_returns_df[\"normalized_episode_reward_mean\"]\n",
    "\n",
    "        # threshold is 0.05 (max - min) return (i.e. normalized return)\n",
    "        # we scale by sqrt(n) to account for size of population\n",
    "        threshold = 0.05 * np.sqrt(norm_df.shape[0])\n",
    "        cluster = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            metric=\"euclidean\",\n",
    "            distance_threshold=threshold,\n",
    "        )\n",
    "        # transpose to cluster based on returns against each policy\n",
    "        # i.e. each feature is returns of different policy in population against the \n",
    "        #      given policy \n",
    "        cluster.fit(norm_df.to_numpy().T)\n",
    "\n",
    "        plot_dendrogram(\n",
    "            cluster, \n",
    "            truncate_mode='level', \n",
    "            labels=pw_returns_df.index.to_list(),\n",
    "            ax=env_axes[1],\n",
    "        )\n",
    "        env_axes[1].plot(\n",
    "            [0, 1000],\n",
    "            [threshold, threshold],\n",
    "            linestyle=\"--\",\n",
    "            color=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "        env_axes[1].set(xlabel=\"Policy\", ylabel=\"Pairwise L2 Distance\")\n",
    "        env_axes[1].xaxis.set_tick_params(rotation=90)\n",
    "\n",
    "    if plot_individual_envs:\n",
    "        assert fig is not None\n",
    "        fig.tight_layout()\n",
    "        if save_results:\n",
    "            if not show_dendrogram:\n",
    "                file_name = \"pairwise_returns.pdf\"  \n",
    "            else:\n",
    "                file_name = \"pairwise_returns_with_dendrogram.pdf\"\n",
    "            fig.savefig(\n",
    "                ALL_ENV_DATA[full_env_id].env_data_dir / file_name, \n",
    "                bbox_inches=\"tight\"\n",
    "            )\n",
    "\n",
    "\n",
    "if not plot_individual_envs:\n",
    "    assert fig is not None\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per population Diversity\n",
    "fig, axes = plt.subplots(nrows=NUM_ENVS, ncols=2, figsize=(10, (NUM_ENVS * 4) + 2))\n",
    "\n",
    "for row, (env_id, env_data) in enumerate(ALL_ENV_DATA.items()):\n",
    "    agent_id = env_data.agent_id\n",
    "    print(env_id, agent_id)\n",
    "    for col, pop_id in enumerate([\"P0\", \"P1\"]):\n",
    "        env_df = div_results_df[\n",
    "            (div_results_df[\"env_agent_id\"] == env_id) &\n",
    "            (div_results_df[\"agent_id\"] == agent_id) &\n",
    "            (div_results_df[\"policy_pop_id\"] == pop_id) &\n",
    "            (div_results_df[\"co_team_pop_id\"] == pop_id)\n",
    "        ]\n",
    "\n",
    "        pw_returns = env_df.pivot(\n",
    "            index=\"policy_name\", \n",
    "            columns=\"co_team_name\", \n",
    "            values=\"episode_reward_mean\"\n",
    "        )\n",
    "        pw_returns = pw_returns.sort_index(\n",
    "            axis='columns',\n",
    "            level=None,\n",
    "            inplace=False,\n",
    "            key=sort_index_fn\n",
    "        )\n",
    "        pw_returns = pw_returns.sort_index(\n",
    "            axis='rows',\n",
    "            level=None,\n",
    "            inplace=False,\n",
    "            key=sort_index_fn\n",
    "        )\n",
    "        sns.heatmap(\n",
    "            data=pw_returns,\n",
    "            ax=axes[row, col],\n",
    "            annot=True,\n",
    "            cmap=\"YlGnBu\",\n",
    "            fmt=\".2f\",\n",
    "            square=True,\n",
    "            annot_kws={\"fontsize\": 6}\n",
    "        )\n",
    "        axes[row, col].set_title(f\"Env: {env_id}, Pop: {pop_id}\")\n",
    "        axes[row, col].set(xlabel=\"Other Agent Policy\", ylabel=\"Policy\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgbls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
