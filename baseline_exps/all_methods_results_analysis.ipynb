{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analysis of all methods results\n",
                "\n",
                "Here we explore the performance of RL, Planning, and RL+Planning across the different environments.\n",
                "\n",
                "We will look at their mean performance (i.e. episode returns) across the different environments. Looking at both in-distribution (planning population matches the test population) and out-of-distribution (planning population does not match the test population) settings.\n",
                "\n",
                "**Note** for RL and RL+Planning each experiment run was repeated 5 times (once for each RL policy seed), so we average the results across these 5 runs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from posggym_baselines.config import REPO_DIR\n",
                "\n",
                "sys.path.insert(0, str(REPO_DIR / \"baseline_exps\"))\n",
                "import exp_utils\n",
                "\n",
                "sns.set_theme(style=\"white\")\n",
                "sns.set_context(\"paper\", font_scale=1.5)\n",
                "sns.set_palette(\"colorblind\")\n",
                "\n",
                "SAVE_RESULTS = True\n",
                "PRL_VERSION = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load environment information and other formatting stuff.\n",
                "\n",
                "print(\"Experiment Environment:\")\n",
                "ALL_ENV_DATA = exp_utils.load_all_env_data()\n",
                "for k in ALL_ENV_DATA:\n",
                "    print(k)\n",
                "\n",
                "NUM_ENVS = len(ALL_ENV_DATA)\n",
                "\n",
                "# figure parameters\n",
                "N_COLS = 2 if PRL_VERSION else 3\n",
                "N_ROWS = (NUM_ENVS // N_COLS) + int(NUM_ENVS % N_COLS > 0)\n",
                "\n",
                "\n",
                "RETURN_RANGES = {\n",
                "    \"CooperativeReaching-v0\": (0, 1),\n",
                "    \"Driving-v1\": (-1, 1),\n",
                "    \"LevelBasedForaging-v3\": (0, 1),\n",
                "    \"PredatorPrey-v0\": (0, 1),\n",
                "    \"PursuitEvasion-v1_i0\": (-1, 1),\n",
                "    \"PursuitEvasion-v1_i1\": (-1, 1)\n",
                "}\n",
                "\n",
                "# Algorithms which have both in- and out-of-distribution results\n",
                "ID_VS_OOD_ALGS = [\"IPOMCP\", \"POTMMCP\", \"RL-BR\", \"COMBINED\"]\n",
                "\n",
                "# Plot Formatting\n",
                "alg_order = [\n",
                "    \"INTMCP\",\n",
                "    \"IPOMCP\",\n",
                "    \"POMCP\",\n",
                "    \"POTMMCP\",\n",
                "    \"RL-BR\",\n",
                "    \"COMBINED\",\n",
                "]\n",
                "# ref: https://seaborn.pydata.org/tutorial/color_palettes.html\n",
                "alg_color_palette = sns.color_palette(\"tab10\")\n",
                "alg_palette={\n",
                "    # planning methods\n",
                "    \"INTMCP\": alg_color_palette[0],\n",
                "    \"IPOMCP\": alg_color_palette[1],\n",
                "    \"POMCP\": alg_color_palette[2],\n",
                "    \"POTMMCP\": alg_color_palette[3],\n",
                "    # rl\n",
                "    \"RL-BR\": alg_color_palette[4],\n",
                "    # combined\n",
                "    \"COMBINED\": alg_color_palette[6],\n",
                "}\n",
                "alg_dashes = {\n",
                "    # planning methods\n",
                "    \"INTMCP\": (2, 2),\n",
                "    \"IPOMCP\": (2, 2),\n",
                "    \"POMCP\": (2, 2),\n",
                "    \"POTMMCP\": (2, 2),\n",
                "    # rl\n",
                "    \"RL-BR\": \"\",\n",
                "    # combined\n",
                "    \"COMBINED\": (1, 1),\n",
                "}\n",
                "alg_dashes = {\n",
                "    # planning methods\n",
                "    \"INTMCP\": \"\",\n",
                "    \"IPOMCP\": \"\",\n",
                "    \"POMCP\": \"\",\n",
                "    \"POTMMCP\": \"\",\n",
                "    # rl\n",
                "    \"RL-BR\": (2, 2),\n",
                "    # combined\n",
                "    \"COMBINED\": (4, 2),\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Utility function to add In/Out of Distribution labels\n",
                "def get_in_out_dist_label(row):\n",
                "    if row[\"Algorithm\"] in [\"POMCP\", \"INTMCP\"]:\n",
                "        return False\n",
                "    return bool(row[\"Planning Population\"] == row[\"Test Population\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Planning Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "planning_results_dfs = []\n",
                "for env_id, env_data in ALL_ENV_DATA.items():\n",
                "    env_planning_results = pd.read_csv(env_data.planning_results_file)\n",
                "    env_planning_results[\"full_env_id\"] = env_id\n",
                "    env_planning_results[\"Type\"] = \"Planning\"\n",
                "    planning_results_dfs.append(env_planning_results)\n",
                "\n",
                "planning_results_df = pd.concat(planning_results_dfs, ignore_index=True)\n",
                "planning_results_df.rename(\n",
                "    columns={\n",
                "        \"alg\": \"Algorithm\",\n",
                "        \"planning_pop_id\": \"Planning Population\",\n",
                "        \"test_pop_id\": \"Test Population\",\n",
                "        \"return\": \"Return\",\n",
                "        \"discounted_return\": \"Discounted Return\",\n",
                "        \"len\": \"Episode Length\",\n",
                "    },\n",
                "    inplace=True,\n",
                ")\n",
                "\n",
                "planning_results_df[\"In Distribution\"] = planning_results_df.apply(\n",
                "    get_in_out_dist_label, axis=1\n",
                ")\n",
                "\n",
                "planning_results_df.sort_values(\n",
                "    by=[\n",
                "        \"Algorithm\", \n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\", \n",
                "        \"search_time_limit\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "max_search_time = planning_results_df[\"search_time_limit\"].max()\n",
                "print(planning_results_df[\"search_time_limit\"].unique())\n",
                "\n",
                "del planning_results_dfs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## RL Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "br_results_dfs = []\n",
                "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
                "    env_br_results_df = pd.read_csv(env_data.rl_br_results_file)\n",
                "    env_br_results_df[\"full_env_id\"] = full_env_id\n",
                "    env_br_results_df[\"Type\"] = \"Learning\"\n",
                "    br_results_dfs.append(env_br_results_df)\n",
                "\n",
                "br_results_df = pd.concat(br_results_dfs, ignore_index=True)\n",
                "br_results_df.rename(\n",
                "    columns={\n",
                "        \"train_pop\": \"Planning Population\",\n",
                "        \"test_pop\": \"Test Population\",\n",
                "        \"return\": \"Return\",\n",
                "        \"discounted_return\": \"Discounted Return\",\n",
                "        \"train_seed\": \"rl_policy_seed\",\n",
                "        \"len\": \"Episode Length\",\n",
                "    },\n",
                "    inplace=True,\n",
                ")\n",
                "\n",
                "br_results_df[\"Algorithm\"] = \"RL-BR\"\n",
                "br_results_df[\"In Distribution\"] = br_results_df.apply(\n",
                "    get_in_out_dist_label, axis=1\n",
                ")\n",
                "\n",
                "\n",
                "br_results_df.sort_values(\n",
                "    by=[\n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "del br_results_dfs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Combined (RL+Planning) Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "combined_results_dfs = []\n",
                "for env_id, env_data in ALL_ENV_DATA.items():\n",
                "    env_combined_results = pd.read_csv(env_data.combined_results_file)\n",
                "    env_combined_results[\"full_env_id\"] = env_id\n",
                "    env_combined_results[\"Type\"] = \"Combined\"\n",
                "    combined_results_dfs.append(env_combined_results)\n",
                "\n",
                "combined_results_df = pd.concat(combined_results_dfs, ignore_index=True)\n",
                "combined_results_df.rename(\n",
                "    columns={\n",
                "        \"alg\": \"Algorithm\",\n",
                "        \"planning_pop_id\": \"Planning Population\",\n",
                "        \"test_pop_id\": \"Test Population\",\n",
                "        \"return\": \"Return\",\n",
                "        \"discounted_return\": \"Discounted Return\",\n",
                "        \"len\": \"Episode Length\",\n",
                "    },\n",
                "    inplace=True,\n",
                ")\n",
                "\n",
                "combined_results_df[\"In Distribution\"] = combined_results_df.apply(\n",
                "    get_in_out_dist_label, axis=1\n",
                ")\n",
                "\n",
                "combined_results_df.sort_values(\n",
                "    by=[\n",
                "        \"Algorithm\", \n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\", \n",
                "        \"search_time_limit\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "assert (combined_results_df[\"rl_policy_pop_id\"] == combined_results_df[\"Planning Population\"]).all()\n",
                "combined_results_df.drop(columns=[\"rl_policy_pop_id\"], inplace=True)\n",
                "print(combined_results_df[\"search_time_limit\"].unique())\n",
                "\n",
                "del combined_results_dfs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## All Data\n",
                "\n",
                "Here we combine planning, RL, and combined results into a single Dataframe."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Need to add search_time_limit to br_results_df\n",
                "# We duplicate the DF and set the search_time_limit to the max and min values\n",
                "# This will produce a horizontal line in the plots :)\n",
                "min_search_time = min(\n",
                "    planning_results_df[\"search_time_limit\"].min(),\n",
                "    combined_results_df[\"search_time_limit\"].min(),\n",
                ")\n",
                "max_search_time = max(\n",
                "    planning_results_df[\"search_time_limit\"].max(),\n",
                "    combined_results_df[\"search_time_limit\"].max(),\n",
                ")\n",
                "br_results_df[\"search_time_limit\"] = max_search_time\n",
                "min_br_results_df = br_results_df.copy(deep=True)\n",
                "min_br_results_df[\"search_time_limit\"] = min_search_time\n",
                "\n",
                "# combine planning, combined, and rl results together\n",
                "all_results_df = pd.concat(\n",
                "    [\n",
                "        planning_results_df, \n",
                "        combined_results_df, \n",
                "        br_results_df,\n",
                "        min_br_results_df\n",
                "    ],\n",
                "    ignore_index=True\n",
                ")\n",
                "\n",
                "def normalize_return(row):\n",
                "    min_return, max_return = RETURN_RANGES[row[\"full_env_id\"]]\n",
                "    return (row[\"Return\"] - min_return) / (max_return - min_return)\n",
                "\n",
                "all_results_df[\"Normalized Return\"] = all_results_df.apply(normalize_return, axis=1)\n",
                "\n",
                "all_results_df.sort_values(\n",
                "    by=[\n",
                "        \"Algorithm\", \n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\", \n",
                "        \"search_time_limit\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "all_results_df[\"rl_policy_seed\"] = all_results_df[\"rl_policy_seed\"].astype(\"category\")\n",
                "all_results_df[\"num\"] = all_results_df[\"num\"].astype(\"category\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generalization Data\n",
                "\n",
                "Compute results with Generalization Gap: in-distribution - out-of-distribution returns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# remove unused columns\n",
                "gg_df = all_results_df[\n",
                "    [\n",
                "        \"Algorithm\",\n",
                "        \"full_env_id\",\n",
                "        \"Planning Population\",\n",
                "        \"Test Population\",\n",
                "        \"search_time_limit\",\n",
                "        \"Return\",\n",
                "        \"In Distribution\",\n",
                "        # \"rl_policy_seed\",\n",
                "    ]\n",
                "]\n",
                "gg_df = gg_df[\n",
                "    gg_df[\"Algorithm\"].isin([\"COMBINED\", \"RL-BR\", \"IPOMCP\", \"POTMMCP\"])\n",
                "]\n",
                "\n",
                "# average over episodes\n",
                "gg_gb = gg_df.groupby(\n",
                "    [\n",
                "        \"Algorithm\",\n",
                "        \"full_env_id\",\n",
                "        \"Planning Population\",\n",
                "        \"Test Population\",\n",
                "        \"search_time_limit\",\n",
                "        \"In Distribution\",\n",
                "    ]\n",
                ").agg({\"Return\": [\"mean\", \"count\", \"std\", \"var\"]}).reset_index()\n",
                "gg_gb.columns = [\"_\".join(x) if x[1] != '' else x[0] for x in gg_gb.columns.ravel()]\n",
                "# gg_gb\n",
                "\n",
                "gg_df = gg_gb[\n",
                "    gg_gb[\"In Distribution\"] == True\n",
                "].merge(\n",
                "    gg_gb[gg_gb[\"In Distribution\"] == False],\n",
                "    on=[\n",
                "        \"Algorithm\",\n",
                "        \"full_env_id\",\n",
                "        \"Planning Population\",\n",
                "        \"search_time_limit\",\n",
                "        # \"rl_policy_seed\",\n",
                "    ],\n",
                "    suffixes=(\"\", \"_test\"),\n",
                ")\n",
                "gg_df[\"Generalization Gap\"] = gg_df[\"Return_mean\"] - gg_df[\"Return_mean_test\"]\n",
                "gg_df[\"Generalization Gap CI\"] = 1.96 * np.sqrt(\n",
                "    gg_df[\"Return_var\"] / gg_df[\"Return_count\"]\n",
                "    + gg_df[\"Return_var_test\"] / gg_df[\"Return_count_test\"]\n",
                ")\n",
                "print(gg_df[\"Algorithm\"].unique())\n",
                "gg_df\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Overall Results\n",
                "\n",
                "Here we plot both in- and out-of-distribution performance averaged over environments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for return_key in [\"Return\", \"Normalized Return\"]:\n",
                "    df = all_results_df.groupby(\n",
                "        [\n",
                "            \"Algorithm\",\n",
                "            \"full_env_id\",\n",
                "            \"search_time_limit\",\n",
                "            \"In Distribution\",\n",
                "        ],\n",
                "        as_index=False\n",
                "    ).agg({f\"{return_key}\": [\"mean\", \"count\", \"std\", \"var\"]})\n",
                "    df.columns = [\"_\".join(x).strip() if x[1] != '' else x[0] for x in df.columns.values]\n",
                "\n",
                "    fig, axs = plt.subplots(\n",
                "        nrows=1, \n",
                "        ncols=2, \n",
                "        figsize=(6, 4.125),\n",
                "        sharey=True,\n",
                "    )\n",
                "    search_times = all_results_df[\"search_time_limit\"].unique().tolist()\n",
                "    search_times.sort()\n",
                "\n",
                "    for in_dist, ax in zip([True, False], axs):\n",
                "        df_dist = df[(df[\"In Distribution\"] == in_dist)]\n",
                "\n",
                "        for alg in alg_order:\n",
                "            if alg not in df_dist[\"Algorithm\"].unique():\n",
                "                continue\n",
                "            df_alg = df_dist[(df_dist[\"Algorithm\"] == alg)]\n",
                "            x = []\n",
                "            y = []\n",
                "            yerr = []\n",
                "            for t in search_times:\n",
                "                if t not in df_alg[\"search_time_limit\"].unique():\n",
                "                    continue\n",
                "                df_alg_t = df_alg[(df_alg[\"search_time_limit\"] == t)]\n",
                "                mean = df_alg_t[f\"{return_key}_mean\"].mean()\n",
                "                var = df_alg_t[f\"{return_key}_var\"].sum() / len(df_alg_t[f\"{return_key}_count\"])**2\n",
                "                ci = 1.96 * np.sqrt(var / df_alg_t[f\"{return_key}_count\"].sum())\n",
                "                x.append(t)\n",
                "                y.append(mean)\n",
                "                yerr.append(ci)\n",
                "            ax.plot(\n",
                "                x,\n",
                "                y,\n",
                "                label=alg,\n",
                "                color=alg_palette[alg],\n",
                "                linestyle=\"-\" if isinstance(alg_dashes[alg], str) else (0, alg_dashes[alg]),\n",
                "            )\n",
                "            ax.fill_between(\n",
                "                x,\n",
                "                np.array(y) - np.array(yerr),\n",
                "                np.array(y) + np.array(yerr),\n",
                "                alpha=0.2,\n",
                "                color=alg_palette[alg],\n",
                "            )\n",
                "\n",
                "        ax.set_xlabel(\"Search Time (s)\")\n",
                "        if in_dist:\n",
                "            ax.set_ylabel(f\"Mean {return_key}\")\n",
                "        ax.set_title(\"In Distribution\" if in_dist else \"Out of Distribution\")\n",
                "        ax.yaxis.set_tick_params(labelleft=True)\n",
                "\n",
                "    lines, labels = axs[1].get_legend_handles_labels()\n",
                "    if PRL_VERSION:\n",
                "        fig.legend(\n",
                "            lines,\n",
                "            labels,\n",
                "            loc=\"lower center\",\n",
                "            bbox_to_anchor=(0.5, 0.0),\n",
                "            ncol=3,\n",
                "            frameon=False,\n",
                "            fontsize=12,\n",
                "            # title=\"Algorithm\",\n",
                "        )\n",
                "        # left, bottom, right, top\n",
                "        fig.tight_layout(rect=(0.0, 0.125, 1.0, 1.0))\n",
                "    else:\n",
                "        fig.legend(\n",
                "            lines,\n",
                "            labels,\n",
                "            loc=\"center left\",\n",
                "            bbox_to_anchor=(1.0, 0.5),\n",
                "            ncol=1,\n",
                "            frameon=False,\n",
                "            fontsize=12,\n",
                "            title=\"Algorithm\",\n",
                "        )\n",
                "        fig.tight_layout()\n",
                "        \n",
                "\n",
                "    if SAVE_RESULTS:\n",
                "        print(\"saving figure\")\n",
                "        fig.savefig(\n",
                "            str(exp_utils.ENV_DATA_DIR / \"figures\" / f\"all_methods_{return_key}_ID_and_OOD.pdf\"), \n",
                "            bbox_inches=\"tight\"\n",
                "        )\n",
                "    del fig, axs, df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# In-Distribution Results\n",
                "\n",
                "Here we look specifically at the in-distribution performance of all methods in each environment separately."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mean Return\n",
                "\n",
                "Dimensions:\n",
                "\n",
                "- `y-axis`: mean episode return\n",
                "- `x-axis`: search time\n",
                "- `z-axis/hue`: algorithm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "g = sns.relplot(\n",
                "    data=all_results_df[all_results_df[\"In Distribution\"] == True],\n",
                "    x=\"search_time_limit\",\n",
                "    y=\"Return\",\n",
                "    hue=\"Algorithm\",\n",
                "    style=\"Algorithm\",\n",
                "    col=\"full_env_id\",\n",
                "    col_wrap=N_COLS,\n",
                "    hue_order=[a for a in alg_order if a not in [\"INTMCP\", \"POMCP\"]],\n",
                "    legend=\"full\",\n",
                "    palette=alg_palette,\n",
                "    markers=False,\n",
                "    dashes=alg_dashes,\n",
                "    kind=\"line\",\n",
                "    height=2.75 if PRL_VERSION else 4,\n",
                "    aspect=1.2 if PRL_VERSION else 1,\n",
                "    facet_kws={\n",
                "        \"sharey\": False, \n",
                "        \"sharex\": False\n",
                "    },\n",
                ")\n",
                "\n",
                "for i, (col_key, ax) in enumerate(g.axes_dict.items()):\n",
                "    ax.set_title(col_key)\n",
                "    if i % N_COLS == 0:\n",
                "        ax.set_ylabel(\"Mean Return\")\n",
                "    if i >= (N_ROWS -1) * N_COLS:\n",
                "        ax.set_xlabel(\"Search Time (s)\")\n",
                "\n",
                "if PRL_VERSION:\n",
                "    sns.move_legend(\n",
                "        g, \n",
                "        loc=\"lower center\",\n",
                "        ncol=4,\n",
                "        bbox_to_anchor=(0.5, 0.0),\n",
                "        title=None,\n",
                "        frameon=False\n",
                "    )\n",
                "    g.tight_layout(rect=(0.0, 0.04, 1.0, 1.0))\n",
                "\n",
                "if SAVE_RESULTS:\n",
                "    print(\"saving figure\")\n",
                "    g.savefig(\n",
                "        exp_utils.ENV_DATA_DIR / \"figures\" / \"all_methods_returns_ID_allenvs.pdf\", \n",
                "        bbox_inches=\"tight\"\n",
                "    )\n",
                "del g"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Same as above except a seperate figure for each env\n",
                "for env_id in all_results_df[\"full_env_id\"].unique():\n",
                "    g = sns.relplot(\n",
                "        data=all_results_df[\n",
                "            (all_results_df[\"In Distribution\"] == True)\n",
                "            & (all_results_df[\"full_env_id\"] == env_id)\n",
                "        ],\n",
                "        x=\"search_time_limit\",\n",
                "        y=\"Return\",\n",
                "        hue=\"Algorithm\",\n",
                "        style=\"Algorithm\",\n",
                "        hue_order=[a for a in alg_order if a not in [\"INTMCP\", \"POMCP\"]],\n",
                "        legend=\"full\",\n",
                "        palette=alg_palette,\n",
                "        markers=False,\n",
                "        dashes=alg_dashes,\n",
                "        kind=\"line\",\n",
                "        height=4,\n",
                "        aspect=1,\n",
                "    )\n",
                "    g.ax.set_title(env_id)\n",
                "    g.ax.set_ylabel(\"Mean Return\")\n",
                "    g.ax.set_xlabel(\"Search Time (s)\")\n",
                "\n",
                "    if SAVE_RESULTS:\n",
                "        print(\"saving figure\")\n",
                "        g.savefig(\n",
                "            exp_utils.ENV_DATA_DIR / \"figures\" / f\"all_methods_returns_ID_{env_id}.pdf\", \n",
                "            bbox_inches=\"tight\"\n",
                "        )\n",
                "del g"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "g = sns.relplot(\n",
                "    data=all_results_df[all_results_df[\"In Distribution\"] == True],\n",
                "    x=\"search_time_limit\",\n",
                "    y=\"Return\",\n",
                "    hue=\"Algorithm\",\n",
                "    style=\"Algorithm\",\n",
                "    row=\"full_env_id\",\n",
                "    col=\"Planning Population\",\n",
                "    hue_order=[a for a in alg_order if a not in [\"INTMCP\", \"POMCP\"]],\n",
                "    legend=\"full\",\n",
                "    palette=alg_palette,\n",
                "    markers=False,\n",
                "    dashes=alg_dashes,\n",
                "    kind=\"line\",\n",
                "    height=3,\n",
                "    aspect=1.5,\n",
                "    facet_kws={\n",
                "        \"sharey\": \"row\", \n",
                "        \"sharex\": True\n",
                "    },\n",
                ")\n",
                "\n",
                "for col_key, ax in g.axes_dict.items():\n",
                "    ax.set_title(col_key)\n",
                "    ax.set_xlabel(\"Search Time Limit (s)\")\n",
                "    ax.set_ylabel(\"Mean Return\")\n",
                "\n",
                "del g"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Average Episode Length\n",
                "\n",
                "Here we plot the average episode length of each algorithm in each environment. We show results using the maximum search time for the planning and combine methods.\n",
                "\n",
                "Dimensions:\n",
                "\n",
                "- `y-axis`: mean episode length\n",
                "- `x-axis`: environment\n",
                "- `z-axis/hue`: algorithm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "g = sns.catplot(\n",
                "    data=all_results_df[\n",
                "        (all_results_df[\"In Distribution\"] == True)\n",
                "        & (all_results_df[\"search_time_limit\"] == max_search_time)\n",
                "    ],\n",
                "    x=\"full_env_id\",\n",
                "    y=\"Episode Length\",\n",
                "    hue=\"Algorithm\",\n",
                "    hue_order=[a for a in alg_order if a not in [\"INTMCP\", \"POMCP\"]],\n",
                "    legend=\"full\",\n",
                "    palette=sns.color_palette(\"colorblind\")[:4],\n",
                "    kind=\"bar\",\n",
                "    height=4,\n",
                "    aspect=1.5,\n",
                ")\n",
                "\n",
                "g.set_xticklabels(rotation=90)\n",
                "g.set_axis_labels(\"\", \"Mean Episode Length\")\n",
                "\n",
                "if SAVE_RESULTS:\n",
                "    print(\"saving figure\")\n",
                "    g.savefig(\n",
                "        exp_utils.ENV_DATA_DIR / \"figures\" / \"all_methods_lens_ID_allenvs.pdf\", \n",
                "        bbox_inches=\"tight\"\n",
                "    )\n",
                "del g"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Out-of-Distribution Results\n",
                "\n",
                "Here we look at the out-of-distribution performance of all methods in each environment separately."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mean Return\n",
                "\n",
                "Dimensions:\n",
                "\n",
                "- `y-axis`: mean episode return\n",
                "- `x-axis`: search time\n",
                "- `z-axis/hue`: algorithm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "g = sns.relplot(\n",
                "    data=all_results_df[all_results_df[\"In Distribution\"] == False],\n",
                "    x=\"search_time_limit\",\n",
                "    y=\"Return\",\n",
                "    hue=\"Algorithm\",\n",
                "    style=\"Algorithm\",\n",
                "    col=\"full_env_id\",\n",
                "    col_wrap=N_COLS,\n",
                "    hue_order=alg_order,\n",
                "    legend=\"full\",\n",
                "    palette=alg_palette,\n",
                "    markers=False,\n",
                "    dashes=alg_dashes,\n",
                "    kind=\"line\",\n",
                "    height=2.75 if PRL_VERSION else 4,\n",
                "    aspect=1.2 if PRL_VERSION else 1,\n",
                "    facet_kws={\n",
                "        \"sharey\": False, \n",
                "        \"sharex\": False\n",
                "    },\n",
                ")\n",
                "\n",
                "for i, (col_key, ax) in enumerate(g.axes_dict.items()):\n",
                "    ax.set_title(col_key)\n",
                "    if i % N_COLS == 0:\n",
                "        ax.set_ylabel(\"Mean Return\")\n",
                "    if i >= (N_ROWS - 1) * N_COLS:\n",
                "        ax.set_xlabel(\"Search Time (s)\")\n",
                "\n",
                "if PRL_VERSION:\n",
                "    sns.move_legend(\n",
                "        g, \n",
                "        loc=\"lower center\",\n",
                "        ncol=3,\n",
                "        bbox_to_anchor=(0.5, 0.0),\n",
                "        title=None,\n",
                "        frameon=False\n",
                "    )\n",
                "    g.tight_layout(rect=(0.0, 0.075, 1.0, 1.0))\n",
                "\n",
                "if SAVE_RESULTS:\n",
                "    print(\"saving figure\")\n",
                "    g.savefig(\n",
                "        exp_utils.ENV_DATA_DIR / \"figures\" / \"all_methods_returns_OOD_allenvs.pdf\", \n",
                "        bbox_inches=\"tight\"\n",
                "    )\n",
                "del g"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Generalization (In- vs Out-of-Distribution) Results\n",
                "\n",
                "Here we look at the gap between in-distribution and out-of-distribution performance of each algorithm."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mean Return\n",
                "\n",
                "In the first plot we show the mean return of each algorithm for in and out of distribution settings, averaged across all environments.\n",
                "\n",
                "- `x-axis`: Search Time\n",
                "- `y-axis`: Mean Return\n",
                "- `hue/z-axis`: In Distribution (or not)\n",
                "- `col`: Algorithm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for return_key in [\"Return\", \"Normalized Return\"]:\n",
                "    df = all_results_df[\n",
                "            all_results_df[\"Algorithm\"].isin(ID_VS_OOD_ALGS)\n",
                "        ].groupby(\n",
                "            [\n",
                "                \"Algorithm\",\n",
                "                \"full_env_id\",\n",
                "                \"search_time_limit\",\n",
                "                \"In Distribution\",\n",
                "            ],\n",
                "            as_index=False\n",
                "        ).agg({f\"{return_key}\": [\"mean\", \"count\", \"std\", \"var\"]})\n",
                "    df.columns = [\"_\".join(x).strip() if x[1] != '' else x[0] for x in df.columns.values]\n",
                "\n",
                "    fig, axs = plt.subplots(\n",
                "        nrows=1, \n",
                "        ncols=len(ID_VS_OOD_ALGS), \n",
                "        figsize=(10, 4.125),\n",
                "        sharey=True,\n",
                "        squeeze=False\n",
                "    )\n",
                "    search_times = all_results_df[\"search_time_limit\"].unique().tolist()\n",
                "    search_times.sort()\n",
                "\n",
                "    i = 0\n",
                "    for alg in alg_order:\n",
                "        if alg not in df[\"Algorithm\"].unique():\n",
                "            continue\n",
                "        df_alg = df[(df[\"Algorithm\"] == alg)]\n",
                "        ax = axs[0][i]\n",
                "        i += 1\n",
                "\n",
                "        for in_dist in [True, False]:\n",
                "            df_dist = df_alg[(df_alg[\"In Distribution\"] == in_dist)]\n",
                "            \n",
                "            x = []\n",
                "            y = []\n",
                "            yerr = []\n",
                "            for t in search_times:\n",
                "                if t not in df_dist[\"search_time_limit\"].unique():\n",
                "                    continue\n",
                "                df_dist_t = df_dist[(df_dist[\"search_time_limit\"] == t)]\n",
                "                mean = df_dist_t[f\"{return_key}_mean\"].mean()\n",
                "                var = df_dist_t[f\"{return_key}_var\"].sum() / len(df_dist_t[f\"{return_key}_count\"])**2\n",
                "                ci = 1.96 * np.sqrt(var / df_dist_t[f\"{return_key}_count\"].sum())\n",
                "                x.append(t)\n",
                "                y.append(mean)\n",
                "                yerr.append(ci)\n",
                "            ax.plot(x, y, label=in_dist)\n",
                "            ax.fill_between(\n",
                "                x,\n",
                "                np.array(y) - np.array(yerr),\n",
                "                np.array(y) + np.array(yerr),\n",
                "                alpha=0.2,\n",
                "            )\n",
                "\n",
                "        ax.set_xlabel(\"Search Time (s)\")\n",
                "        if i == 1:\n",
                "            ax.set_ylabel(f\"Mean {return_key}\")\n",
                "        ax.set_title(alg)\n",
                "        ax.yaxis.set_tick_params(labelleft=True)\n",
                "\n",
                "    lines, labels = axs[0][0].get_legend_handles_labels()\n",
                "    if PRL_VERSION:\n",
                "        fig.legend(\n",
                "            lines,\n",
                "            labels,\n",
                "            loc=\"lower center\",\n",
                "            bbox_to_anchor=(0.5, 0.0),\n",
                "            ncol=3,\n",
                "            frameon=False,\n",
                "            fontsize=12,\n",
                "            title=\"In Dist.\",\n",
                "        )\n",
                "        # left, bottom, right, top\n",
                "        fig.tight_layout(rect=(0.0, 0.125, 1.0, 1.0))\n",
                "    else:\n",
                "        fig.legend(\n",
                "            lines,\n",
                "            labels,\n",
                "            loc=\"center left\",\n",
                "            bbox_to_anchor=(1.0, 0.5),\n",
                "            ncol=1,\n",
                "            frameon=False,\n",
                "            fontsize=12,\n",
                "            title=\"In Dist.\",\n",
                "        )\n",
                "        fig.tight_layout()\n",
                "\n",
                "    if SAVE_RESULTS:\n",
                "        print(\"saving figure\")\n",
                "        fig.savefig(\n",
                "            str(exp_utils.ENV_DATA_DIR / \"figures\" / f\"all_methods_{return_key}_ID_vs_OOD.pdf\"), \n",
                "            bbox_inches=\"tight\"\n",
                "        )\n",
                "\n",
                "    del fig, axs, df\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generalization Gap\n",
                "\n",
                "Here we plot ID - OOD performance for each algorithm. We show results for planning and combined methods using the maximum search time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# remove unused columns\n",
                "return_key = \"Normalized Return\"\n",
                "gg_df = all_results_df[\n",
                "    all_results_df[\"search_time_limit\"] == max_search_time\n",
                "][\n",
                "    [\n",
                "        \"Algorithm\",\n",
                "        \"full_env_id\",\n",
                "        \"Planning Population\",\n",
                "        \"Test Population\",\n",
                "        \"search_time_limit\",\n",
                "        return_key,\n",
                "        \"In Distribution\",\n",
                "        # \"rl_policy_seed\",\n",
                "    ]\n",
                "]\n",
                "gg_df = gg_df[\n",
                "    gg_df[\"Algorithm\"].isin([\"COMBINED\", \"RL-BR\", \"IPOMCP\", \"POTMMCP\"])\n",
                "]\n",
                "\n",
                "# average over episodes\n",
                "gg_gb = gg_df.groupby(\n",
                "    [\n",
                "        \"Algorithm\",\n",
                "        \"full_env_id\",\n",
                "        \"Planning Population\",\n",
                "        \"Test Population\",\n",
                "        \"search_time_limit\",\n",
                "        \"In Distribution\",\n",
                "    ]\n",
                ").agg({return_key: [\"mean\", \"count\", \"std\", \"var\"]}).reset_index()\n",
                "gg_gb.columns = [\"_\".join(x) if x[1] != '' else x[0] for x in gg_gb.columns.ravel()]\n",
                "# gg_gb\n",
                "\n",
                "# merge ID and OOD rows into single row\n",
                "gg_df = gg_gb[\n",
                "    gg_gb[\"In Distribution\"] == True\n",
                "].merge(\n",
                "    gg_gb[gg_gb[\"In Distribution\"] == False],\n",
                "    on=[\n",
                "        \"Algorithm\",\n",
                "        \"full_env_id\",\n",
                "        \"Planning Population\",\n",
                "        \"search_time_limit\",\n",
                "        # \"rl_policy_seed\",\n",
                "    ],\n",
                "    suffixes=(\"\", \"_test\"),\n",
                ")\n",
                "\n",
                "# compute generalization gap\n",
                "gg_df[\"Generalization Gap\"] = (\n",
                "    gg_df[f\"{return_key}_mean\"] - gg_df[f\"{return_key}_mean_test\"]\n",
                ")\n",
                "# compute CI by combining variance of ID and OOD\n",
                "gg_df[\"Generalization Gap CI\"] = 1.96 * np.sqrt(\n",
                "    ((gg_df[f\"{return_key}_var\"] + gg_df[f\"{return_key}_var_test\"]))\n",
                ") / (\n",
                "    gg_df[[f\"{return_key}_count\", f\"{return_key}_count_test\"]].min(axis=1)\n",
                ")\n",
                "print(gg_df[\"Algorithm\"].unique())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gg_key = \"Generalization Gap\"\n",
                "# Average over populations\n",
                "overall_gg_df = gg_df.groupby(\n",
                "    [\n",
                "        \"Algorithm\",\n",
                "        \"full_env_id\",\n",
                "    ],\n",
                "    as_index=False\n",
                ").agg({\n",
                "    gg_key: [\"mean\"],\n",
                "    f\"{gg_key} CI\": [\"mean\"]\n",
                "})\n",
                "overall_gg_df.columns = [\n",
                "    \"_\".join(x).strip() if x[1] != '' else x[0] \n",
                "    for x in overall_gg_df.columns.values\n",
                "]\n",
                "\n",
                "fig, ax = plt.subplots(\n",
                "    nrows=1, \n",
                "    ncols=1, \n",
                "    figsize=(4, 4),\n",
                "    sharey=True,\n",
                ")\n",
                "\n",
                "x = np.arange(len(overall_gg_df[\"Algorithm\"].unique()))\n",
                "ys = []\n",
                "yerrs = []\n",
                "for alg in ID_VS_OOD_ALGS:\n",
                "    df_alg = overall_gg_df[(overall_gg_df[\"Algorithm\"] == alg)]\n",
                "    ys.append(df_alg[f\"{gg_key}_mean\"].mean())\n",
                "    yerrs.append(df_alg[f\"{gg_key} CI_mean\"].mean())\n",
                "ax.bar(\n",
                "    x,\n",
                "    ys,\n",
                "    yerr=yerrs,\n",
                "    tick_label=ID_VS_OOD_ALGS,\n",
                "    color=sns.color_palette(\"colorblind\"),\n",
                ")\n",
                "\n",
                "ax.set_xticklabels(ID_VS_OOD_ALGS, rotation=90)\n",
                "ax.set_xlabel(\"Algorithm\")\n",
                "ax.set_ylabel(gg_key)\n",
                "ax.yaxis.set_tick_params(labelleft=True)\n",
                "fig.tight_layout()\n",
                "\n",
                "if SAVE_RESULTS:\n",
                "    print(\"saving figure\")\n",
                "    fig.savefig(\n",
                "        str(exp_utils.ENV_DATA_DIR / \"figures\" / f\"all_methods_{gg_key}.pdf\"), \n",
                "        bbox_inches=\"tight\"\n",
                "    )\n",
                "del fig, ax, overall_gg_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Driving-v1\n",
                "\n",
                "Here we do a bit of a deeper dive into the performance of each algorithm in the  `Driving-v1` environment.\n",
                "\n",
                "In particular we can look at the distribution of episode lengths as well as the proportion of episodes that ended with a crash, timeout, or success."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "driving_df = all_results_df[\n",
                "    (all_results_df[\"full_env_id\"] == \"Driving-v1\")\n",
                "    & (all_results_df[\"In Distribution\"] == True)\n",
                "]\n",
                "\n",
                "max_search_time = driving_df[\"search_time_limit\"].max()\n",
                "print(max_search_time)\n",
                "\n",
                "driving_df = driving_df[\n",
                "    (driving_df[\"search_time_limit\"] == max_search_time)\n",
                "]\n",
                "\n",
                "crashed_df = driving_df[\n",
                "    (driving_df[\"Return\"] < 0)\n",
                "]\n",
                "success_df = driving_df[\n",
                "    (driving_df[\"Return\"] >= 0.99)\n",
                "]\n",
                "timedout_df = driving_df[\n",
                "    (driving_df[\"Return\"] < 0.99)\n",
                "    & (driving_df[\"Return\"] >= 0)\n",
                "]\n",
                "assert len(driving_df) - len(crashed_df) - len(success_df) - len(timedout_df) == 0\n",
                "\n",
                "for alg in alg_order:\n",
                "    if alg not in driving_df[\"Algorithm\"].unique():\n",
                "        continue\n",
                "    print(f\"\\n{alg}\")\n",
                "    total_eps = len(driving_df[driving_df[\"Algorithm\"] == alg])\n",
                "    num_crashed = len(crashed_df[crashed_df[\"Algorithm\"] == alg])\n",
                "    num_success = len(success_df[success_df[\"Algorithm\"] == alg])\n",
                "    num_timeout = len(timedout_df[timedout_df[\"Algorithm\"] == alg])\n",
                "\n",
                "    print(f\"Total:    {total_eps}\")\n",
                "    print(f\"Crashed:  {num_crashed} ({num_crashed / total_eps * 100:.2f}%)\")\n",
                "    print(f\"Success:  {num_success} ({num_success / total_eps * 100:.2f}%)\")\n",
                "    print(f\"Timedout: {num_timeout} ({num_timeout / total_eps * 100:.2f}%)\")\n",
                "\n",
                "# latex table output\n",
                "print(\"\\n\\n\")\n",
                "print(\"Algorithm & Crashed & Success & Timedout \\\\\\\\\")\n",
                "for alg in alg_order:\n",
                "    if alg not in driving_df[\"Algorithm\"].unique():\n",
                "        continue\n",
                "    total_eps = len(driving_df[driving_df[\"Algorithm\"] == alg])\n",
                "    num_crashed = len(crashed_df[crashed_df[\"Algorithm\"] == alg])\n",
                "    num_success = len(success_df[success_df[\"Algorithm\"] == alg])\n",
                "    num_timeout = len(timedout_df[timedout_df[\"Algorithm\"] == alg])\n",
                "    print(f\"{alg} & ${num_crashed / total_eps * 100:.2f}\\%$ & ${num_success / total_eps * 100:.2f}\\%$ & ${num_timeout / total_eps * 100:.2f}\\%$ \\\\\\\\\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Belief Statistics\n",
                "\n",
                "Here we plot the belief accuracy of the combined and POTMMCP methods."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Combined Beliefs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "combined_belief_dfs = []\n",
                "for full_env_id in ALL_ENV_DATA:\n",
                "    print(full_env_id)\n",
                "    env_belief_results = pd.read_csv(\n",
                "        ALL_ENV_DATA[full_env_id].env_data_dir / \"combined_belief_per_step_results.csv\"\n",
                "    )\n",
                "    env_belief_results[\"full_env_id\"] = full_env_id\n",
                "\n",
                "    env_step_limit = max(\n",
                "        int(c.split(\"_\")[-1]) \n",
                "        for c in env_belief_results.columns \n",
                "        if c.startswith(\"belief_state_acc_\")\n",
                "    )\n",
                "    env_belief_results[\"step_limit\"] = env_step_limit\n",
                "\n",
                "    # drop unused columns\n",
                "    # keep only id columns and per step belief stats (remove mean belief stats)\n",
                "    id_cols = [\n",
                "        \"alg\", \n",
                "        \"full_env_id\", \n",
                "        \"planning_pop_id\", \n",
                "        \"test_pop_id\", \n",
                "        \"rl_policy_seed\",\n",
                "        \"search_time_limit\", \n",
                "        \"step_limit\",\n",
                "        \"num\"\n",
                "    ]\n",
                "    cols_to_keep = [*id_cols] + [\n",
                "        c for c in env_belief_results.columns \n",
                "        if c.startswith(\"belief_\") and c.split(\"_\")[-1] != \"acc\"\n",
                "    ]\n",
                "    env_belief_results.drop(\n",
                "        columns=[c for c in env_belief_results.columns if c not in cols_to_keep], \n",
                "        inplace=True\n",
                "    )\n",
                "\n",
                "    # convert from wide to long format for per step belief stats\n",
                "    stub_names = [\n",
                "        k for k in [\n",
                "            \"belief_state_acc\", \n",
                "            \"belief_history_acc\", \n",
                "            \"belief_action_acc\", \n",
                "            \"belief_policy_acc\"\n",
                "        ]\n",
                "        if any(c.startswith(k) for c in env_belief_results.columns)\n",
                "    ]\n",
                "\n",
                "    env_belief_results = pd.wide_to_long(\n",
                "        env_belief_results, \n",
                "        stubnames=stub_names, \n",
                "        i=id_cols, \n",
                "        j=\"step\", \n",
                "        sep=\"_\"\n",
                "    ).reset_index()\n",
                "    combined_belief_dfs.append(env_belief_results)\n",
                "\n",
                "combined_belief_df = pd.concat(combined_belief_dfs, ignore_index=True)\n",
                "combined_belief_df.rename(\n",
                "    columns={\n",
                "        \"planning_pop_id\": \"Planning Population\",\n",
                "        \"test_pop_id\": \"Test Population\",\n",
                "        \"belief_state_acc\": \"Belief State Accuracy\",\n",
                "        \"belief_history_acc\": \"Belief History Accuracy\",\n",
                "        \"belief_action_acc\": \"Belief Action Accuracy\",\n",
                "        \"belief_policy_acc\": \"Belief Policy Accuracy\",\n",
                "        \"search_time_limit\": \"Search Time (s)\",\n",
                "    },\n",
                "    inplace=True,\n",
                ")\n",
                "\n",
                "# Add In/Out of Distribution labels\n",
                "def get_in_out_dist_label(row):\n",
                "    return row[\"Planning Population\"] == row[\"Test Population\"]\n",
                "\n",
                "combined_belief_df[\"In Distribution\"] = combined_belief_df.apply(\n",
                "    get_in_out_dist_label, axis=1\n",
                ")\n",
                "\n",
                "combined_belief_df.sort_values(\n",
                "    by=[\n",
                "        \"alg\", \n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\", \n",
                "        \"Search Time (s)\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "print(combined_belief_df[\"Search Time (s)\"].unique())\n",
                "print(combined_belief_df[\"full_env_id\"].unique())\n",
                "print(combined_belief_df[\"step\"].min(), combined_belief_df[\"step\"].max())\n",
                "\n",
                "# for c in belief_results_df.columns:\n",
                "#     print(c)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot in shared plot\n",
                "for belief_stat_key in [\n",
                "    \"Belief State Accuracy\",\n",
                "    # \"Belief History Accuracy\",\n",
                "    \"Belief Action Accuracy\",\n",
                "    \"Belief Policy Accuracy\",\n",
                "]:\n",
                "    print(belief_stat_key)\n",
                "\n",
                "    if belief_stat_key == \"Belief Policy Accuracy\":\n",
                "        g = sns.relplot(\n",
                "            data=combined_belief_df[combined_belief_df[\"In Distribution\"] == True],\n",
                "            x=\"step\",\n",
                "            y=belief_stat_key,\n",
                "            hue=\"Search Time (s)\",\n",
                "            col_wrap=N_COLS,\n",
                "            kind=\"line\",\n",
                "            col=\"full_env_id\",\n",
                "            height=3,\n",
                "            aspect=1.5,\n",
                "            facet_kws={\n",
                "                \"sharey\": False,\n",
                "                \"sharex\": False, \n",
                "            },\n",
                "        )\n",
                "    else:\n",
                "        g = sns.relplot(\n",
                "            data=combined_belief_df,\n",
                "            x=\"step\",\n",
                "            y=belief_stat_key,\n",
                "            hue=\"Search Time (s)\",\n",
                "            style=\"In Distribution\",\n",
                "            style_order=[True, False],\n",
                "            col_wrap=N_COLS,\n",
                "            kind=\"line\",\n",
                "            col=\"full_env_id\",\n",
                "            height=3,\n",
                "            aspect=1.5,\n",
                "            facet_kws={\n",
                "                \"sharey\": False,\n",
                "                \"sharex\": False, \n",
                "            },\n",
                "        )\n",
                "\n",
                "    for i, (col_key, ax) in enumerate(g.axes_dict.items()):\n",
                "        ax.set_title(f\"{col_key}\")\n",
                "        if i >= (N_ROWS-1) * N_COLS:\n",
                "            ax.set_xlabel(\"Episode Step\")\n",
                "\n",
                "\n",
                "    if PRL_VERSION:\n",
                "        sns.move_legend(\n",
                "            g, \n",
                "            loc=\"lower center\",\n",
                "            ncol=3,\n",
                "            bbox_to_anchor=(0.5, 0.0),\n",
                "            title=None,\n",
                "            frameon=False\n",
                "        )\n",
                "        g.tight_layout(rect=(0.0, 0.1, 1.0, 1.0))\n",
                "\n",
                "    if True:\n",
                "        print(f\"saving {belief_stat_key} figure\")\n",
                "        g.savefig(\n",
                "            exp_utils.ENV_DATA_DIR / \"figures\" / f\"per_step_{belief_stat_key}.pdf\", \n",
                "            bbox_inches=\"tight\"\n",
                "        )\n",
                "\n",
                "    del g"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Planning Beliefs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "planning_belief_dfs = []\n",
                "for full_env_id in ALL_ENV_DATA:\n",
                "    print(full_env_id)\n",
                "    env_belief_results = pd.read_csv(\n",
                "        ALL_ENV_DATA[full_env_id].env_data_dir / \"planning_belief_per_step_results.csv\"\n",
                "    )\n",
                "    env_belief_results[\"full_env_id\"] = full_env_id\n",
                "\n",
                "    env_step_limit = max(\n",
                "        int(c.split(\"_\")[-1]) \n",
                "        for c in env_belief_results.columns \n",
                "        if c.startswith(\"belief_state_acc_\")\n",
                "    )\n",
                "    env_belief_results[\"step_limit\"] = env_step_limit\n",
                "\n",
                "    # drop unused columns\n",
                "    # keep only id columns and per step belief stats (remove mean belief stats)\n",
                "    id_cols = [\n",
                "        \"alg\", \n",
                "        \"full_env_id\", \n",
                "        \"planning_pop_id\", \n",
                "        \"test_pop_id\", \n",
                "        \"search_time_limit\", \n",
                "        \"step_limit\",\n",
                "        \"num\"\n",
                "    ]\n",
                "    cols_to_keep = [*id_cols] + [\n",
                "        c for c in env_belief_results.columns \n",
                "        if c.startswith(\"belief_\") and c.split(\"_\")[-1] != \"acc\"\n",
                "    ]\n",
                "    env_belief_results.drop(\n",
                "        columns=[c for c in env_belief_results.columns if c not in cols_to_keep], \n",
                "        inplace=True\n",
                "    )\n",
                "\n",
                "    # convert from wide to long format for per step belief stats\n",
                "    stub_names = [\n",
                "        k for k in [\n",
                "            \"belief_state_acc\", \n",
                "            \"belief_history_acc\", \n",
                "            \"belief_action_acc\", \n",
                "            \"belief_policy_acc\"\n",
                "        ]\n",
                "        if any(c.startswith(k) for c in env_belief_results.columns)\n",
                "    ]\n",
                "\n",
                "    env_belief_results = pd.wide_to_long(\n",
                "        env_belief_results, \n",
                "        stubnames=stub_names, \n",
                "        i=id_cols, \n",
                "        j=\"step\", \n",
                "        sep=\"_\"\n",
                "    ).reset_index()\n",
                "    planning_belief_dfs.append(env_belief_results)\n",
                "\n",
                "planning_belief_df = pd.concat(planning_belief_dfs, ignore_index=True)\n",
                "planning_belief_df.rename(\n",
                "    columns={\n",
                "        \"alg\": \"Algorithm\",\n",
                "        \"planning_pop_id\": \"Planning Population\",\n",
                "        \"test_pop_id\": \"Test Population\",\n",
                "        \"belief_state_acc\": \"Belief State Accuracy\",\n",
                "        \"belief_history_acc\": \"Belief History Accuracy\",\n",
                "        \"belief_action_acc\": \"Belief Action Accuracy\",\n",
                "        \"belief_policy_acc\": \"Belief Policy Accuracy\",\n",
                "        \"search_time_limit\": \"Search Time (s)\",\n",
                "    },\n",
                "    inplace=True,\n",
                ")\n",
                "\n",
                "# Add In/Out of Distribution labels\n",
                "def get_in_out_dist_label(row):\n",
                "    if row[\"Algorithm\"] in [\"POMCP\", \"INTMCP\"]:\n",
                "        return False\n",
                "    return bool(row[\"Planning Population\"] == row[\"Test Population\"])\n",
                "\n",
                "planning_belief_df[\"In Distribution\"] = planning_belief_df.apply(\n",
                "    get_in_out_dist_label, axis=1\n",
                ")\n",
                "\n",
                "planning_belief_df.sort_values(\n",
                "    by=[\n",
                "        \"Algorithm\", \n",
                "        \"full_env_id\", \n",
                "        \"Planning Population\", \n",
                "        \"Test Population\", \n",
                "        \"Search Time (s)\"\n",
                "    ], \n",
                "    inplace=True\n",
                ")\n",
                "\n",
                "print(planning_belief_df[\"Search Time (s)\"].unique())\n",
                "print(planning_belief_df[\"full_env_id\"].unique())\n",
                "print(planning_belief_df[\"step\"].min(), planning_belief_df[\"step\"].max())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for alg in planning_belief_df[\"Algorithm\"].unique():\n",
                "    if alg in [\"POMCP\", \"INTMCP\"]:\n",
                "                continue\n",
                "\n",
                "    alg_df = planning_belief_df[planning_belief_df[\"Algorithm\"] == alg]\n",
                "    for belief_stat_key in [\n",
                "        \"Belief State Accuracy\",\n",
                "        # \"Belief History Accuracy\",\n",
                "        \"Belief Action Accuracy\",\n",
                "        \"Belief Policy Accuracy\",\n",
                "    ]:\n",
                "        print(alg, belief_stat_key)\n",
                "\n",
                "\n",
                "        if belief_stat_key == \"Belief Policy Accuracy\":\n",
                "            if alg in [\"POMCP\", \"INTMCP\"]:\n",
                "                continue\n",
                "            g = sns.relplot(\n",
                "                data=alg_df[alg_df[\"In Distribution\"] == True],\n",
                "                x=\"step\",\n",
                "                y=belief_stat_key,\n",
                "                hue=\"Search Time (s)\",\n",
                "                col_wrap=N_COLS,\n",
                "                kind=\"line\",\n",
                "                col=\"full_env_id\",\n",
                "                height=3,\n",
                "                aspect=1.5,\n",
                "                facet_kws={\n",
                "                    \"sharey\": False,\n",
                "                    \"sharex\": False, \n",
                "                },\n",
                "            )\n",
                "        else:\n",
                "            g = sns.relplot(\n",
                "                data=alg_df,\n",
                "                x=\"step\",\n",
                "                y=belief_stat_key,\n",
                "                hue=\"Search Time (s)\",\n",
                "                style=\"In Distribution\",\n",
                "                style_order=[True, False],\n",
                "                col_wrap=N_COLS,\n",
                "                kind=\"line\",\n",
                "                col=\"full_env_id\",\n",
                "                height=3,\n",
                "                aspect=1.5,\n",
                "                facet_kws={\n",
                "                    \"sharey\": False,\n",
                "                    \"sharex\": False, \n",
                "                },\n",
                "            )\n",
                "\n",
                "        for i, (col_key, ax) in enumerate(g.axes_dict.items()):\n",
                "            ax.set_title(f\"{col_key}\")\n",
                "            if i >= N_COLS:\n",
                "                ax.set_xlabel(\"Episode Step\")\n",
                "\n",
                "        if True:\n",
                "            print(f\"saving {alg} {belief_stat_key} figure\")\n",
                "            g.savefig(\n",
                "                exp_utils.ENV_DATA_DIR / \"figures\" / f\"{alg}_per_step_{belief_stat_key}.pdf\", \n",
                "                bbox_inches=\"tight\"\n",
                "            )\n",
                "\n",
                "        del g"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Search Statistics\n",
                "\n",
                "Here we look at various statistics of the search process for each algorithm.\n",
                "\n",
                "Each figure is a different statistic, each line is a different environment since we expect some differences between environments based on things like average steps to terminal state. In and out of distribution results are grouped together since we expect and see no different in search statistics between in vs out of distribution.\n",
                "\n",
                "- `x-axis`: Search time\n",
                "- `y-axis`: Search Statistic Values\n",
                "- `col/figures`: Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if False:\n",
                "    for stat_key in [\n",
                "        \"search_time\",\n",
                "        \"update_time\",\n",
                "        \"reinvigoration_time\",\n",
                "        \"evaluation_time\",\n",
                "        \"policy_calls\",\n",
                "        \"inference_time\",\n",
                "        \"search_depth\",\n",
                "        \"num_sims\",\n",
                "        \"mem_usage\",\n",
                "        \"min_value\",\n",
                "        \"max_value\",\n",
                "    ]:\n",
                "        print(stat_key)\n",
                "        stat_df = all_results_df[all_results_df[\"Algorithm\"] != \"RL-BR\"]\n",
                "        stat_min = stat_df[stat_key].min()\n",
                "        stat_max = stat_df[stat_key].max()\n",
                "        use_log_scale = (stat_max / max(1, stat_min)) > 100 and stat_key != \"min_value\"\n",
                "\n",
                "        g = sns.relplot(\n",
                "            data=all_results_df[all_results_df[\"Algorithm\"] != \"RL-BR\"],\n",
                "            x=\"search_time_limit\",\n",
                "            y=stat_key,\n",
                "            hue=\"Algorithm\",\n",
                "            # col_wrap=N_COLS,\n",
                "            row=\"Planning Population\",\n",
                "            col=\"full_env_id\",\n",
                "            kind=\"line\",\n",
                "            facet_kws={\n",
                "                \"sharey\": True, \n",
                "                \"sharex\": True,\n",
                "            },\n",
                "        )\n",
                "\n",
                "        for (row_key, col_key), ax in g.axes_dict.items():\n",
                "            ax.set_title(f\"{row_key} | {col_key}\")\n",
                "            ax.set_xlabel(\"Search Time Limit (s)\")\n",
                "            if use_log_scale:\n",
                "                ax.set_yscale(\"log\")\n",
                "\n",
                "        del g"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pgbls",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
