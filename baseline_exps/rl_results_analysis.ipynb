{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the RL BR policies\n",
    "\n",
    "In this notebook we explore the performance of BR policies trained on two different populations, `P0` and `P1`.\n",
    "\n",
    "Progress:\n",
    "- There is a clear generalization gap for the BR policies for each environment, with some minor exceptions\n",
    "- The relationship between diversity and generalization gap is not clear. It's complicated. I hypothesize there are a two key factors: (1) population diversity, (2) population fitness, but how they affect generalization is not clear. I need to think about this more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from posggym_baselines.config import REPO_DIR\n",
    "\n",
    "sys.path.insert(0, str(REPO_DIR / \"baseline_exps\"))\n",
    "import exp_utils\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_palette(\"colorblind\")\n",
    "# sns.set_palette(\"pastel\")\n",
    "\n",
    "SAVE_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_ENV_DATA = exp_utils.load_all_env_data()\n",
    "for k in ALL_ENV_DATA:\n",
    "    print(k)\n",
    "\n",
    "NUM_ENVS = len(ALL_ENV_DATA)\n",
    "\n",
    "# figure parameters\n",
    "FIGSIZE = (10, 10)\n",
    "N_COLS = min(3, NUM_ENVS)\n",
    "N_ROWS = (NUM_ENVS // N_COLS) + int(NUM_ENVS % N_COLS > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR Policy Learning Curves\n",
    "\n",
    "Here we plot the learning curves for the BR policies trained on `P0` and `P1` for each environment. \n",
    "\n",
    "We use a separate plot for each population for each environment, and plot each training seed as a separate line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cleans the raw data downloaded from wandb\n",
    "# - removing weird names\n",
    "# - removing the __MIN and __MAX columns\n",
    "# - updating column names\n",
    "# - reformating the data to use a seed column instead of separate columns for each seed\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    for pop_id, results_file in env_data.rl_br_training_results_files.items():\n",
    "        results_df = pd.read_csv(results_file)\n",
    "        if \"global_step\" not in results_df.columns:\n",
    "            # already cleaned\n",
    "            continue\n",
    "        \n",
    "        columns_to_drop = []\n",
    "        step_col_to_keep = None\n",
    "        for col in results_df.columns:\n",
    "            if col.endswith(\"__MIN\") or col.endswith(\"__MAX\"):\n",
    "                columns_to_drop.append(col)\n",
    "            elif col != \"global_step\" and col.endswith(\"_step\"):\n",
    "                if step_col_to_keep is None:\n",
    "                    step_col_to_keep = col\n",
    "                else:\n",
    "                    columns_to_drop.append(col)\n",
    "        results_df = results_df.drop(columns=columns_to_drop)\n",
    "\n",
    "        column_rename_map = {}\n",
    "        seeds = []\n",
    "        for col in results_df.columns:\n",
    "            if col == \"global_step\":\n",
    "                column_rename_map[col] = \"step\"\n",
    "            elif col.endswith(\"_step\"):\n",
    "                column_rename_map[col] = \"update\"\n",
    "            else:\n",
    "                assert col.endswith(\"/BR/mean_episode_return\")\n",
    "                tokens = col.split(\"_\")\n",
    "                env_token_idx = tokens.index(env_data.env_id)\n",
    "                seed = int(tokens[env_token_idx + 1])\n",
    "                column_rename_map[col] = seed\n",
    "                seeds.append(seed)\n",
    "\n",
    "        results_df = results_df.rename(columns=column_rename_map)\n",
    "\n",
    "        results_df = results_df.melt(\n",
    "            id_vars=[\"step\", \"update\"], \n",
    "            value_vars=seeds, \n",
    "            var_name=\"seed\", \n",
    "            value_name=\"mean_episode_return\"\n",
    "        )\n",
    "        results_df[\"seed\"] = results_df[\"seed\"].astype(int)\n",
    "        \n",
    "        results_df.to_csv(str(results_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "training_results_df = []\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    env_pop_results_df = []\n",
    "    for pop_id, results_file in env_data.rl_br_training_results_files.items():\n",
    "        results_df = pd.read_csv(results_file)\n",
    "        results_df[\"pop_id\"] = pop_id\n",
    "        env_pop_results_df.append(results_df)\n",
    "    env_pop_results_df = pd.concat(env_pop_results_df)\n",
    "    env_pop_results_df[\"full_env_id\"] = full_env_id\n",
    "    training_results_df.append(env_pop_results_df)\n",
    "\n",
    "training_results_df = pd.concat(training_results_df)\n",
    "\n",
    "full_env_ids = training_results_df[\"full_env_id\"].unique().tolist()\n",
    "full_env_ids.sort()\n",
    "print(\"Full env ids:\", full_env_ids)\n",
    "\n",
    "pop_ids = training_results_df[\"pop_id\"].unique().tolist()\n",
    "pop_ids.sort()\n",
    "print(\"Pop ids:\", pop_ids)\n",
    "\n",
    "seeds = training_results_df[\"seed\"].unique().tolist()\n",
    "seeds.sort()\n",
    "print(\"Seeds:\", seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "pallete = {s: 'grey' for s in seeds}\n",
    "\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, \n",
    "        ncols=2, \n",
    "        figsize=(6, 3), \n",
    "        sharey=True,\n",
    "        sharex=True,\n",
    "    )\n",
    "    env_df = training_results_df[training_results_df[\"full_env_id\"] == full_env_id]\n",
    "    for c, pop_id in enumerate(pop_ids):\n",
    "        ax = axes[c]\n",
    "        pop_df = env_df[env_df[\"pop_id\"] == pop_id]\n",
    "        sns.lineplot(\n",
    "            data=pop_df,\n",
    "            x=\"step\",\n",
    "            y=\"mean_episode_return\",\n",
    "            hue=\"seed\",\n",
    "            palette=pallete,\n",
    "            ax=ax,\n",
    "            legend=False,\n",
    "            alpha=0.5,\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=pop_df,\n",
    "            x=\"step\",\n",
    "            y=\"mean_episode_return\",\n",
    "            ax=ax,\n",
    "            color=sns.color_palette()[0],\n",
    "            legend=False,\n",
    "            errorbar=None,\n",
    "            linewidth=0.75,\n",
    "        )\n",
    "\n",
    "        # Set axis labels\n",
    "        ax.set_ylabel(\"Mean Return\")\n",
    "        ax.set_xlabel(\"Training Step\")\n",
    "        ax.set_title(pop_id)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # if SAVE_RESULTS:\n",
    "    if True:\n",
    "        fig.savefig(str(env_data.env_data_dir / \"rl_br_learning_curve.pdf\"))\n",
    "    fig.suptitle(full_env_id)\n",
    "    fig.subplots_adjust(top=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR Policy Performance against Train and Test populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_results_df = []\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    env_br_results_df = pd.read_csv(env_data.rl_br_results_file)\n",
    "    env_br_results_df[\"full_env_id\"] = full_env_id\n",
    "    br_results_df.append(env_br_results_df)\n",
    "\n",
    "br_results_df = pd.concat(br_results_df)\n",
    "br_results_df.rename(\n",
    "    columns={\n",
    "        \"train_pop\": \"Train Population\",\n",
    "        \"eval_pop\": \"Test Population\",\n",
    "        \"mean_returns\": \"Mean Return\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Add In/Out of Distribution labels\n",
    "def get_in_out_dist_label(row):\n",
    "    return row[\"Train Population\"] == row[\"Test Population\"]\n",
    "\n",
    "br_results_df[\"In Distribution\"] = br_results_df.apply(\n",
    "    get_in_out_dist_label, axis=1\n",
    ")\n",
    "\n",
    "\n",
    "br_results_df.sort_values(\n",
    "    by=[\n",
    "        \"full_env_id\", \n",
    "        \"Train Population\", \n",
    "        \"Test Population\"\n",
    "    ], \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in (\"point\", \"violin\"):\n",
    "    kwargs = {}\n",
    "    if kind == \"bar\":\n",
    "        kwargs[\"capsize\"] = 0.1\n",
    "    elif kind == \"violin\":\n",
    "        kwargs[\"cut\"] = 2\n",
    "\n",
    "    plot = sns.catplot(\n",
    "        data=br_results_df,\n",
    "        x=\"Train Population\",\n",
    "        y=\"Mean Return\",\n",
    "        hue=\"Test Population\",\n",
    "        col=\"full_env_id\",\n",
    "        col_wrap=N_COLS,\n",
    "        kind=kind,\n",
    "        sharey=False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        plot.figure.savefig(\n",
    "            exp_utils.ENV_DATA_DIR / f\"rl_br_P0vP1_by_env_results_{kind}.png\", \n",
    "            bbox_inches=\"tight\"\n",
    "        )\n",
    "\n",
    "    del plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR Policy In-Distribution vs Out-of-Distribution Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in (\"bar\", \"violin\"):\n",
    "    kwargs = {}\n",
    "    if kind == \"bar\":\n",
    "        kwargs[\"capsize\"] = 0.1\n",
    "    elif kind == \"violin\":\n",
    "        kwargs[\"cut\"] = 0\n",
    "\n",
    "    plot = sns.catplot(\n",
    "        data=br_results_df,\n",
    "        x=\"In Distribution\",\n",
    "        y=\"Mean Return\",\n",
    "        col=\"full_env_id\",\n",
    "        col_wrap=N_COLS,\n",
    "        kind=kind,\n",
    "        sharey=False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # plot.set_xticklabels(rotation=90)\n",
    "\n",
    "    # if SAVE_RESULTS:\n",
    "    if True:\n",
    "        plot.figure.savefig(\n",
    "            exp_utils.ENV_DATA_DIR / f\"rl_br_idvood_by_env_results_{kind}.pdf\", \n",
    "            bbox_inches=\"tight\"\n",
    "        )\n",
    "\n",
    "    plot.figure.tight_layout()\n",
    "    del plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR Policy Generalization Gap\n",
    "\n",
    "The generalization gap of the BR Policy is the difference in performance between the train and test populations. We calculate this by taking the difference between the mean performance of the train and test populations.\n",
    "\n",
    "Specifically, for each seed, we calculate the mean performance of the train and test populations. Then, we take the difference between the two means. Finally, we take the mean of the differences across all seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_df = br_results_df[\n",
    "    br_results_df[\"In Distribution\"] == True  # noqa: E712\n",
    "].merge(\n",
    "    br_results_df[br_results_df[\"In Distribution\"] == False],    # noqa: E712\n",
    "    on=[\"env_id\", \"full_env_id\", \"train_seed\", \"Train Population\"],\n",
    "    suffixes=(\"\", \"_test\"),\n",
    ")\n",
    "\n",
    "gg_df[\"Generalization Gap\"] = gg_df[\"Mean Return_test\"] - gg_df[\"Mean Return\"]\n",
    "\n",
    "for kind in (\"bar\", \"violin\"):\n",
    "    gg_plot = sns.catplot(\n",
    "        data=gg_df,\n",
    "        x=\"Train Population\",\n",
    "        y=\"Generalization Gap\",\n",
    "        col=\"full_env_id\",\n",
    "        col_wrap=N_COLS,\n",
    "        kind=kind,\n",
    "        sharey=True,\n",
    "    )\n",
    "    gg_plot.refline(x=None, y=0.0, linestyle=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Diversity\n",
    "\n",
    "We calculate the diversity of a population of policies by taking the mean of the pairwise distances between the returns of all policies in the population. We use the Euclidean distance as our distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all features together\n",
    "# x = \"Mean Pairwise L2 Distance\"\n",
    "# y = \"Generalization Gap\"\n",
    "# hue/z = \"Mean Pairwise Return\"\n",
    "\n",
    "# Get BR results averaged across seeds\n",
    "all_df = br_results.groupby(\n",
    "    [\"full_env_id\", \"Train Population\", \"Test Population\"]\n",
    ").agg(\n",
    "    {\"Mean Return\": \"mean\"}\n",
    ").reset_index()\n",
    "\n",
    "all_df.sort_values(by=[\"full_env_id\", \"Train Population\", \"Test Population\"], inplace=True)\n",
    "\n",
    "all_df[\"Train\"] = all_df.apply(lambda row: row[\"Train Population\"] == row[\"Test Population\"], axis=1)\n",
    "\n",
    "\n",
    "pop_df = all_df[\n",
    "    all_df[\"Train\"] == True  # noqa: E712\n",
    "].merge(\n",
    "    all_df[all_df[\"Train\"] == False],    # noqa: E712\n",
    "    on=[\"full_env_id\", \"Train Population\"],\n",
    "    suffixes=(\"\", \"_test\"),\n",
    ")\n",
    "pop_df[\"Generalization Gap\"] = pop_df[\"Mean Return_test\"] - pop_df[\"Mean Return\"]\n",
    "# pop_df\n",
    "\n",
    "div_df = pop_div_results[\n",
    "    [\"Env ID\", \"Population\", \"Mean Pairwise L2 Distance\", \"Mean Pairwise Return\"]\n",
    "].copy()\n",
    "\n",
    "pop_df = pop_df.merge(\n",
    "    div_df,\n",
    "    left_on=[\"full_env_id\", \"Train Population\"],\n",
    "    right_on=[\"Env ID\", \"Population\"],\n",
    "    suffixes=(\"\", \"_div\"),\n",
    ")\n",
    "pop_df.drop(columns=[\"Env ID\", \"Population\"], inplace=True)\n",
    "\n",
    "# drop PursuitEvasion-v1_i0 and PursuitEvasion-v1_i1\n",
    "pop_df = pop_df[pop_df[\"full_env_id\"] != \"PursuitEvasion-v1_i0\"]\n",
    "pop_df = pop_df[pop_df[\"full_env_id\"] != \"PursuitEvasion-v1_i1\"]\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=pop_df,\n",
    "    x=\"Mean Pairwise L2 Distance\",\n",
    "    y=\"Generalization Gap\",\n",
    "    hue=\"Mean Pairwise Return\",\n",
    "    palette=\"YlGnBu\",\n",
    "    size=\"Mean Pairwise Return\",\n",
    "    sizes=(50, 200),\n",
    ")\n",
    "\n",
    "pop_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgbls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
