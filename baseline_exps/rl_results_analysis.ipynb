{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the RL BR policies\n",
    "\n",
    "In this notebook we explore the performance of BR policies trained on two different populations, `P0` and `P1`.\n",
    "\n",
    "Progress:\n",
    "- There is a clear generalization gap for the BR policies for each environment, with some minor exceptions\n",
    "- The relationship between diversity and generalization gap is not clear. It's complicated. I hypothesize there are a two key factors: (1) population diversity, (2) population fitness, but how they affect generalization is not clear. I need to think about this more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from posggym_baselines.config import REPO_DIR\n",
    "\n",
    "sys.path.insert(0, str(REPO_DIR / \"baseline_exps\"))\n",
    "import exp_utils\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "SAVE_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_ENV_DATA = exp_utils.load_all_env_data()\n",
    "for k in ALL_ENV_DATA:\n",
    "    print(k)\n",
    "\n",
    "NUM_ENVS = len(ALL_ENV_DATA)\n",
    "\n",
    "# figure parameters\n",
    "FIGSIZE = (10, 10)\n",
    "N_COLS = min(3, NUM_ENVS)\n",
    "N_ROWS = (NUM_ENVS // N_COLS) + int(NUM_ENVS % N_COLS > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_results_df = []\n",
    "for full_env_id, env_data in ALL_ENV_DATA.items():\n",
    "    env_br_results_df = pd.read_csv(env_data.rl_br_results_file)\n",
    "    env_br_results_df[\"full_env_id\"] = full_env_id\n",
    "    br_results_df.append(env_br_results_df)\n",
    "\n",
    "br_results_df = pd.concat(br_results_df)\n",
    "br_results_df.rename(\n",
    "    columns={\n",
    "        \"train_pop\": \"Train Population\",\n",
    "        \"eval_pop\": \"Test Population\",\n",
    "        \"mean_returns\": \"Mean Return\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Add In/Out of Distribution labels\n",
    "def get_in_out_dist_label(row):\n",
    "    return row[\"Train Population\"] == row[\"Test Population\"]\n",
    "\n",
    "br_results_df[\"In Distribution\"] = br_results_df.apply(\n",
    "    get_in_out_dist_label, axis=1\n",
    ")\n",
    "\n",
    "\n",
    "br_results_df.sort_values(\n",
    "    by=[\n",
    "        \"full_env_id\", \n",
    "        \"Train Population\", \n",
    "        \"Test Population\"\n",
    "    ], \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR Policy Performance against Train and Test populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in (\"point\", \"violin\"):\n",
    "    kwargs = {}\n",
    "    if kind == \"bar\":\n",
    "        kwargs[\"capsize\"] = 0.1\n",
    "    elif kind == \"violin\":\n",
    "        kwargs[\"cut\"] = 2\n",
    "\n",
    "    plot = sns.catplot(\n",
    "        data=br_results_df,\n",
    "        x=\"Train Population\",\n",
    "        y=\"Mean Return\",\n",
    "        hue=\"Test Population\",\n",
    "        col=\"full_env_id\",\n",
    "        col_wrap=N_COLS,\n",
    "        kind=kind,\n",
    "        sharey=False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    if SAVE_RESULTS:\n",
    "        plot.figure.savefig(\n",
    "            exp_utils.ENV_DATA_DIR / f\"rl_br_P0vP1_by_env_results_{kind}.png\", \n",
    "            bbox_inches=\"tight\"\n",
    "        )\n",
    "\n",
    "    del plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR Policy In-Distribution vs Out-of-Distribution Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in (\"bar\", \"violin\"):\n",
    "    kwargs = {}\n",
    "    if kind == \"bar\":\n",
    "        kwargs[\"capsize\"] = 0.1\n",
    "    elif kind == \"violin\":\n",
    "        kwargs[\"cut\"] = 0\n",
    "\n",
    "    plot = sns.catplot(\n",
    "        data=br_results_df,\n",
    "        x=\"In Distribution\",\n",
    "        y=\"Mean Return\",\n",
    "        col=\"full_env_id\",\n",
    "        col_wrap=N_COLS,\n",
    "        kind=kind,\n",
    "        sharey=False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # plot.set_xticklabels(rotation=90)\n",
    "\n",
    "    # if SAVE_RESULTS:\n",
    "    if True:\n",
    "        plot.figure.savefig(\n",
    "            exp_utils.ENV_DATA_DIR / f\"rl_br_idvood_by_env_results_{kind}.pdf\", \n",
    "            bbox_inches=\"tight\"\n",
    "        )\n",
    "\n",
    "    plot.figure.tight_layout()\n",
    "    del plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR Policy Generalization Gap\n",
    "\n",
    "The generalization gap of the BR Policy is the difference in performance between the train and test populations. We calculate this by taking the difference between the mean performance of the train and test populations.\n",
    "\n",
    "Specifically, for each seed, we calculate the mean performance of the train and test populations. Then, we take the difference between the two means. Finally, we take the mean of the differences across all seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_df = br_results_df[\n",
    "    br_results_df[\"In Distribution\"] == True  # noqa: E712\n",
    "].merge(\n",
    "    br_results_df[br_results_df[\"In Distribution\"] == False],    # noqa: E712\n",
    "    on=[\"env_id\", \"full_env_id\", \"train_seed\", \"Train Population\"],\n",
    "    suffixes=(\"\", \"_test\"),\n",
    ")\n",
    "\n",
    "gg_df[\"Generalization Gap\"] = gg_df[\"Mean Return_test\"] - gg_df[\"Mean Return\"]\n",
    "\n",
    "for kind in (\"bar\", \"violin\"):\n",
    "    gg_plot = sns.catplot(\n",
    "        data=gg_df,\n",
    "        x=\"Train Population\",\n",
    "        y=\"Generalization Gap\",\n",
    "        col=\"full_env_id\",\n",
    "        col_wrap=N_COLS,\n",
    "        kind=kind,\n",
    "        sharey=True,\n",
    "    )\n",
    "    gg_plot.refline(x=None, y=0.0, linestyle=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Diversity\n",
    "\n",
    "We calculate the diversity of a population of policies by taking the mean of the pairwise distances between the returns of all policies in the population. We use the Euclidean distance as our distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all features together\n",
    "# x = \"Mean Pairwise L2 Distance\"\n",
    "# y = \"Generalization Gap\"\n",
    "# hue/z = \"Mean Pairwise Return\"\n",
    "\n",
    "# Get BR results averaged across seeds\n",
    "all_df = br_results.groupby(\n",
    "    [\"full_env_id\", \"Train Population\", \"Test Population\"]\n",
    ").agg(\n",
    "    {\"Mean Return\": \"mean\"}\n",
    ").reset_index()\n",
    "\n",
    "all_df.sort_values(by=[\"full_env_id\", \"Train Population\", \"Test Population\"], inplace=True)\n",
    "\n",
    "all_df[\"Train\"] = all_df.apply(lambda row: row[\"Train Population\"] == row[\"Test Population\"], axis=1)\n",
    "\n",
    "\n",
    "pop_df = all_df[\n",
    "    all_df[\"Train\"] == True  # noqa: E712\n",
    "].merge(\n",
    "    all_df[all_df[\"Train\"] == False],    # noqa: E712\n",
    "    on=[\"full_env_id\", \"Train Population\"],\n",
    "    suffixes=(\"\", \"_test\"),\n",
    ")\n",
    "pop_df[\"Generalization Gap\"] = pop_df[\"Mean Return_test\"] - pop_df[\"Mean Return\"]\n",
    "# pop_df\n",
    "\n",
    "div_df = pop_div_results[\n",
    "    [\"Env ID\", \"Population\", \"Mean Pairwise L2 Distance\", \"Mean Pairwise Return\"]\n",
    "].copy()\n",
    "\n",
    "pop_df = pop_df.merge(\n",
    "    div_df,\n",
    "    left_on=[\"full_env_id\", \"Train Population\"],\n",
    "    right_on=[\"Env ID\", \"Population\"],\n",
    "    suffixes=(\"\", \"_div\"),\n",
    ")\n",
    "pop_df.drop(columns=[\"Env ID\", \"Population\"], inplace=True)\n",
    "\n",
    "# drop PursuitEvasion-v1_i0 and PursuitEvasion-v1_i1\n",
    "pop_df = pop_df[pop_df[\"full_env_id\"] != \"PursuitEvasion-v1_i0\"]\n",
    "pop_df = pop_df[pop_df[\"full_env_id\"] != \"PursuitEvasion-v1_i1\"]\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=pop_df,\n",
    "    x=\"Mean Pairwise L2 Distance\",\n",
    "    y=\"Generalization Gap\",\n",
    "    hue=\"Mean Pairwise Return\",\n",
    "    palette=\"YlGnBu\",\n",
    "    size=\"Mean Pairwise Return\",\n",
    "    sizes=(50, 200),\n",
    ")\n",
    "\n",
    "pop_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgbls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
